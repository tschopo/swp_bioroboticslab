{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T09:52:11.186659Z",
     "start_time": "2019-03-18T09:52:11.181267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=theano\n",
      "env: THEANO_FLAGS=floatX=float32,device=cpu\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND=theano\n",
    "%env THEANO_FLAGS=floatX=float32,device=cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T09:52:13.997993Z",
     "start_time": "2019-03-18T09:52:12.008121Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport bb_behavior\n",
    "%aimport bb_behavior.plot\n",
    "%aimport bb_behavior.tracking\n",
    "%aimport bb_behavior.tracking.pipeline\n",
    "\n",
    "import bb_behavior\n",
    "import bb_behavior.plot\n",
    "import bb_behavior.tracking\n",
    "import bb_behavior.tracking.pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T09:52:16.100658Z",
     "start_time": "2019-03-18T09:52:16.084301Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook # progress bar\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from bb_tracking.data.constants import DETKEY\n",
    "#from bb_tracking.tracking import score_id_sim_v\n",
    "from bb_tracking.tracking import distance_orientations_v, distance_positions_v\n",
    "\n",
    "from bb_behavior.tracking.pipeline import detect_markers_in_video\n",
    "from bb_behavior.tracking.pipeline import track_detections_dataframe\n",
    "from bb_behavior.tracking.pipeline import display_tracking_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T09:52:36.289429Z",
     "start_time": "2019-03-18T09:52:20.400112Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tscho/.local/lib/python3.6/site-packages/keras/backend/theano_backend.py:1032: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode='max')\n",
      "/home/tscho/.local/lib/python3.6/site-packages/keras/backend/theano_backend.py:1032: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode='max')\n",
      "/home/tscho/.local/lib/python3.6/site-packages/keras/backend/theano_backend.py:1032: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode='max')\n"
     ]
    }
   ],
   "source": [
    "from bb_behavior.tracking.pipeline import get_default_pipeline\n",
    "default_pipeline = None\n",
    "default_pipeline = get_default_pipeline(localizer_threshold=\"0.50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T09:52:36.321773Z",
     "start_time": "2019-03-18T09:52:36.306606Z"
    },
    "code_folding": [
     7
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hilfsfunktionen\n",
    "def filename_to_datestring(filname):\n",
    "    \"\"\"\n",
    "    filename can be path\n",
    "    \"\"\"\n",
    "    return os.path.split(filname)[-1].split('.')[0].split('_')[1]\n",
    "\n",
    "def datestring_to_filename(datestring, prefix=\"e00_\"):\n",
    "    return config[\"videos_dir\"] + prefix + datestring + \".h264\"\n",
    "\n",
    "def string_to_timestamp(datestring):\n",
    "    \"\"\" \n",
    "    params\n",
    "        string: format 2018-08-19-01-08-13\n",
    "    output\n",
    "        unix timestamp (float)\n",
    "    \"\"\"\n",
    "    \n",
    "    return time.mktime(time.strptime(datestring, \"%Y-%m-%d-%H-%M-%S\"))\n",
    "\n",
    "def timestamp_to_string(timestamp):\n",
    "    return time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime(timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T09:52:36.361314Z",
     "start_time": "2019-03-18T09:52:36.334429Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get all videos between timestamp_in and timestamp_out\n",
    "def get_videos_between(timestamp_in, timestamp_out, all_paths):\n",
    "    \"\"\" returns all video between timestamp_in and timestamp out (inclusive) \"\"\"\n",
    "    \n",
    "    mask = (all_paths['video'] >= timestamp_in) & (all_paths['video'] <= timestamp_out)\n",
    "    return list(all_paths[mask]['video'])\n",
    "\n",
    "def loadGTD(path):\n",
    "    # read in the test data csv\n",
    "    test_data = pd.read_csv(path)\n",
    "\n",
    "    # convert the full filenames to string timestamps, and sort by timestamp_in\n",
    "    test_data['video'] = test_data['video'].apply(lambda x: filename_to_datestring(x))\n",
    "    test_data['video_start_time'] = test_data['timestamp_in'].apply(lambda x: filename_to_datestring(x))\n",
    "    test_data['video_end_time'] = test_data['timestamp_out'].apply(lambda x: filename_to_datestring(x))\n",
    "    test_data.sort_values(['video_start_time'], inplace=True)\n",
    "\n",
    "    test_data.drop('timestamp_in', 1, inplace=True)\n",
    "    test_data.drop('timestamp_out', 1, inplace=True)\n",
    "    test_data.drop('video', 1, inplace=True)\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T09:52:36.498748Z",
     "start_time": "2019-03-18T09:52:36.379930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bee_id</th>\n",
       "      <th>in_direction</th>\n",
       "      <th>out_direction</th>\n",
       "      <th>video_start_time</th>\n",
       "      <th>video_end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1970</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-02-21-37</td>\n",
       "      <td>2018-08-19-02-22-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>855</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-05-25-51</td>\n",
       "      <td>2018-08-19-05-25-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2018-08-19-05-25-51</td>\n",
       "      <td>2018-08-19-05-25-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8692</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2018-08-19-06-35-41</td>\n",
       "      <td>2018-08-19-06-35-41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1191</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-07-10-38</td>\n",
       "      <td>2018-08-19-07-10-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1671</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-07-10-38</td>\n",
       "      <td>2018-08-19-07-10-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1788</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-07-16-49</td>\n",
       "      <td>2018-08-19-07-16-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>749</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2018-08-19-07-16-49</td>\n",
       "      <td>2018-08-19-07-16-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3925</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2018-08-19-07-47-52</td>\n",
       "      <td>2018-08-19-07-47-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>481</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2018-08-19-08-21-08</td>\n",
       "      <td>2018-08-19-08-21-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>388</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-08-29-06</td>\n",
       "      <td>2018-08-19-08-29-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>396</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-08-29-06</td>\n",
       "      <td>2018-08-19-08-29-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3312</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2018-08-19-08-29-06</td>\n",
       "      <td>2018-08-19-08-29-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3682</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2018-08-19-08-40-07</td>\n",
       "      <td>2018-08-19-08-40-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>420</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2018-08-19-09-28-45</td>\n",
       "      <td>2018-08-19-09-28-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1066</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-09-28-45</td>\n",
       "      <td>2018-08-19-09-28-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1568</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2018-08-19-09-47-39</td>\n",
       "      <td>2018-08-19-09-48-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>446</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2018-08-19-09-47-39</td>\n",
       "      <td>2018-08-19-09-48-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>420</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-09-48-00</td>\n",
       "      <td>2018-08-19-09-48-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1325</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-09-55-28</td>\n",
       "      <td>2018-08-19-09-55-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1086</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2018-08-19-09-55-49</td>\n",
       "      <td>2018-08-19-09-55-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>850</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-11-45-47</td>\n",
       "      <td>2018-08-19-11-45-47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1401</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>2018-08-19-11-45-47</td>\n",
       "      <td>2018-08-19-11-45-47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>469</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-11-45-47</td>\n",
       "      <td>2018-08-19-11-45-47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>362</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-11-45-47</td>\n",
       "      <td>2018-08-19-11-45-47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>334</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-11-55-18</td>\n",
       "      <td>2018-08-19-11-55-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1596</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-12-02-32</td>\n",
       "      <td>2018-08-19-12-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1282</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-12-03-14</td>\n",
       "      <td>2018-08-19-12-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1149</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-12-03-14</td>\n",
       "      <td>2018-08-19-12-03-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1597</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-12-03-14</td>\n",
       "      <td>2018-08-19-12-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>793</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2018-08-19-16-52-31</td>\n",
       "      <td>2018-08-19-16-52-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1174</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-16-52-52</td>\n",
       "      <td>2018-08-19-16-52-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1301</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>2018-08-19-16-55-15</td>\n",
       "      <td>2018-08-19-16-55-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>793</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>2018-08-19-16-55-15</td>\n",
       "      <td>2018-08-19-16-56-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1056</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>2018-08-19-16-55-15</td>\n",
       "      <td>2018-08-19-16-55-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1301</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-16-58-45</td>\n",
       "      <td>2018-08-19-16-59-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>793</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-16-58-45</td>\n",
       "      <td>2018-08-19-16-59-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>993</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-16-59-06</td>\n",
       "      <td>2018-08-19-16-59-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1301</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-17-00-30</td>\n",
       "      <td>2018-08-19-17-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>301</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-17-01-12</td>\n",
       "      <td>2018-08-19-17-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>793</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2018-08-19-17-06-16</td>\n",
       "      <td>2018-08-19-17-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1337</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-17-42-21</td>\n",
       "      <td>2018-08-19-17-42-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1863</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2018-08-19-17-42-21</td>\n",
       "      <td>2018-08-19-17-43-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>65</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-17-56-40</td>\n",
       "      <td>2018-08-19-17-57-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>301</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2018-08-19-17-57-01</td>\n",
       "      <td>2018-08-19-18-00-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>303</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-18-13-06</td>\n",
       "      <td>2018-08-19-18-13-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>691</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2018-08-19-18-13-06</td>\n",
       "      <td>2018-08-19-18-13-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1554</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-18-25-21</td>\n",
       "      <td>2018-08-19-18-25-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1235</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-18-25-21</td>\n",
       "      <td>2018-08-19-18-25-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1301</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-18-32-42</td>\n",
       "      <td>2018-08-19-18-33-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1520</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-18-33-03</td>\n",
       "      <td>2018-08-19-18-33-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>951</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-18-33-03</td>\n",
       "      <td>2018-08-19-18-33-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>301</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-19-09-58</td>\n",
       "      <td>2018-08-19-21-26-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>301</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-19-09-58</td>\n",
       "      <td>2018-08-19-21-26-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>301</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-19-09-58</td>\n",
       "      <td>2018-08-19-21-26-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>301</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-19-09-58</td>\n",
       "      <td>2018-08-19-21-26-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>301</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-19-09-58</td>\n",
       "      <td>2018-08-19-21-26-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1301</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-19-47-47</td>\n",
       "      <td>2018-08-19-19-48-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1301</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-19-49-32</td>\n",
       "      <td>2018-08-19-19-50-56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1390</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2018-08-19-20-10-16</td>\n",
       "      <td>2018-08-19-20-10-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bee_id in_direction out_direction     video_start_time  \\\n",
       "102    1970         left          left  2018-08-19-02-21-37   \n",
       "0       855        right          left  2018-08-19-05-25-51   \n",
       "1       220         left         right  2018-08-19-05-25-51   \n",
       "24     8692         left         right  2018-08-19-06-35-41   \n",
       "106    1191        right          left  2018-08-19-07-10-38   \n",
       "107    1671        right          left  2018-08-19-07-10-38   \n",
       "56     1788        right          left  2018-08-19-07-16-49   \n",
       "55      749         left         right  2018-08-19-07-16-49   \n",
       "43     3925         left         right  2018-08-19-07-47-52   \n",
       "89      481         left         right  2018-08-19-08-21-08   \n",
       "39      388        right          left  2018-08-19-08-29-06   \n",
       "38      396        right          left  2018-08-19-08-29-06   \n",
       "40     3312         left         right  2018-08-19-08-29-06   \n",
       "41     3682         left         right  2018-08-19-08-40-07   \n",
       "75      420         left         right  2018-08-19-09-28-45   \n",
       "76     1066        right          left  2018-08-19-09-28-45   \n",
       "104    1568         left         right  2018-08-19-09-47-39   \n",
       "103     446         left         right  2018-08-19-09-47-39   \n",
       "105     420        right          left  2018-08-19-09-48-00   \n",
       "97     1325         left          left  2018-08-19-09-55-28   \n",
       "98     1086         left         right  2018-08-19-09-55-49   \n",
       "85      850        right          left  2018-08-19-11-45-47   \n",
       "86     1401        right         right  2018-08-19-11-45-47   \n",
       "87      469        right          left  2018-08-19-11-45-47   \n",
       "88      362        right          left  2018-08-19-11-45-47   \n",
       "34      334        right          left  2018-08-19-11-55-18   \n",
       "71     1596         left          left  2018-08-19-12-02-32   \n",
       "73     1282        right          left  2018-08-19-12-03-14   \n",
       "74     1149         left          left  2018-08-19-12-03-14   \n",
       "72     1597        right          left  2018-08-19-12-03-14   \n",
       "..      ...          ...           ...                  ...   \n",
       "79      793         left         right  2018-08-19-16-52-31   \n",
       "80     1174         left          left  2018-08-19-16-52-52   \n",
       "91     1301        right         right  2018-08-19-16-55-15   \n",
       "90      793        right         right  2018-08-19-16-55-15   \n",
       "92     1056        right         right  2018-08-19-16-55-15   \n",
       "35     1301         left          left  2018-08-19-16-58-45   \n",
       "36      793        right          left  2018-08-19-16-58-45   \n",
       "37      993        right          left  2018-08-19-16-59-06   \n",
       "58     1301        right          left  2018-08-19-17-00-30   \n",
       "59      301         left          left  2018-08-19-17-01-12   \n",
       "60      793         left         right  2018-08-19-17-06-16   \n",
       "83     1337        right          left  2018-08-19-17-42-21   \n",
       "84     1863         left         right  2018-08-19-17-42-21   \n",
       "8        65         left          left  2018-08-19-17-56-40   \n",
       "9       301         left         right  2018-08-19-17-57-01   \n",
       "25      303         left          left  2018-08-19-18-13-06   \n",
       "26      691         left         right  2018-08-19-18-13-06   \n",
       "7      1554         left          left  2018-08-19-18-25-21   \n",
       "6      1235         left          left  2018-08-19-18-25-21   \n",
       "2      1301         left          left  2018-08-19-18-32-42   \n",
       "4      1520         left          left  2018-08-19-18-33-03   \n",
       "3       951         left          left  2018-08-19-18-33-03   \n",
       "42      301         left          left  2018-08-19-19-09-58   \n",
       "100     301         left          left  2018-08-19-19-09-58   \n",
       "5       301         left          left  2018-08-19-19-09-58   \n",
       "78      301         left          left  2018-08-19-19-09-58   \n",
       "32      301         left          left  2018-08-19-19-09-58   \n",
       "77     1301         left          left  2018-08-19-19-47-47   \n",
       "101    1301         left          left  2018-08-19-19-49-32   \n",
       "33     1390         left          left  2018-08-19-20-10-16   \n",
       "\n",
       "          video_end_time  \n",
       "102  2018-08-19-02-22-40  \n",
       "0    2018-08-19-05-25-51  \n",
       "1    2018-08-19-05-25-51  \n",
       "24   2018-08-19-06-35-41  \n",
       "106  2018-08-19-07-10-38  \n",
       "107  2018-08-19-07-10-38  \n",
       "56   2018-08-19-07-16-49  \n",
       "55   2018-08-19-07-16-49  \n",
       "43   2018-08-19-07-47-52  \n",
       "89   2018-08-19-08-21-29  \n",
       "39   2018-08-19-08-29-06  \n",
       "38   2018-08-19-08-29-06  \n",
       "40   2018-08-19-08-29-06  \n",
       "41   2018-08-19-08-40-07  \n",
       "75   2018-08-19-09-28-45  \n",
       "76   2018-08-19-09-28-45  \n",
       "104  2018-08-19-09-48-00  \n",
       "103  2018-08-19-09-48-00  \n",
       "105  2018-08-19-09-48-00  \n",
       "97   2018-08-19-09-55-49  \n",
       "98   2018-08-19-09-55-49  \n",
       "85   2018-08-19-11-45-47  \n",
       "86   2018-08-19-11-45-47  \n",
       "87   2018-08-19-11-45-47  \n",
       "88   2018-08-19-11-45-47  \n",
       "34   2018-08-19-11-55-18  \n",
       "71   2018-08-19-12-03-14  \n",
       "73   2018-08-19-12-03-14  \n",
       "74   2018-08-19-12-03-35  \n",
       "72   2018-08-19-12-03-14  \n",
       "..                   ...  \n",
       "79   2018-08-19-16-52-52  \n",
       "80   2018-08-19-16-52-52  \n",
       "91   2018-08-19-16-55-36  \n",
       "90   2018-08-19-16-56-18  \n",
       "92   2018-08-19-16-55-36  \n",
       "35   2018-08-19-16-59-48  \n",
       "36   2018-08-19-16-59-06  \n",
       "37   2018-08-19-16-59-06  \n",
       "58   2018-08-19-17-01-12  \n",
       "59   2018-08-19-17-01-12  \n",
       "60   2018-08-19-17-06-16  \n",
       "83   2018-08-19-17-42-21  \n",
       "84   2018-08-19-17-43-03  \n",
       "8    2018-08-19-17-57-01  \n",
       "9    2018-08-19-18-00-52  \n",
       "25   2018-08-19-18-13-06  \n",
       "26   2018-08-19-18-13-06  \n",
       "7    2018-08-19-18-25-21  \n",
       "6    2018-08-19-18-25-21  \n",
       "2    2018-08-19-18-33-03  \n",
       "4    2018-08-19-18-33-03  \n",
       "3    2018-08-19-18-33-03  \n",
       "42   2018-08-19-21-26-53  \n",
       "100  2018-08-19-21-26-53  \n",
       "5    2018-08-19-21-26-53  \n",
       "78   2018-08-19-21-26-53  \n",
       "32   2018-08-19-21-26-53  \n",
       "77   2018-08-19-19-48-08  \n",
       "101  2018-08-19-19-50-56  \n",
       "33   2018-08-19-20-10-16  \n",
       "\n",
       "[108 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = loadGTD(\"bees_test.csv\")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T09:58:39.024404Z",
     "start_time": "2019-03-18T09:58:39.014342Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = dict(tag_pixel_diameter=50,\n",
    "              n_frames=None,\n",
    "              confidence_filter_detections=0.08,\n",
    "              confidence_filter_tracks=0.20,\n",
    "              coordinate_scale=1.0,\n",
    "              start_time=None,\n",
    "              fps=10.0,\n",
    "              cam_id=0,\n",
    "              left_leaving_area = 0.3, # Prozente vom Bildschirmrand, zB. bei 1000px und 0.15 -> 0-150px\n",
    "              right_leaving_area = 0.3,\n",
    "              px_x_resolution_vid = 1944,\n",
    "              videos_dir = \"../videos/videos_tags/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T09:52:54.552589Z",
     "start_time": "2019-03-18T09:52:54.453746Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_tracks(paths, save_to_csv = False):\n",
    "    # Hier passiert das eigentliche Tracken und speichern der Ergebnisse:\n",
    "    num_processed_videos = 0\n",
    "    video_data = dict()\n",
    "    frame_info = None\n",
    "    detections = None\n",
    "    bad_paths = []\n",
    "\n",
    "    for path in tqdm_notebook(paths):\n",
    "        start_time = config[\"start_time\"]\n",
    "        cam_id = config[\"cam_id\"]\n",
    "        try:\n",
    "            num_processed_videos += 1\n",
    "\n",
    "            frame_info, detections = detect_markers_in_video(path,\n",
    "                                                          decoder_pipeline=default_pipeline,#pipeline=pipelines(),\n",
    "                                                         tag_pixel_diameter=config[\"tag_pixel_diameter\"],\n",
    "                                                          n_frames=config[\"n_frames\"],\n",
    "                                                          fps=config[\"fps\"],\n",
    "                                                         progress=\"tqdm_notebook\"\n",
    "                                                )\n",
    "            # Sonst würden keine Tracks erkannt werden -> Fehlermeldung\n",
    "            if len(detections[detections['confidence']>=config[\"confidence_filter_detections\"]]) == 0:\n",
    "                continue\n",
    "            tracks = track_detections_dataframe(detections,\n",
    "                                                tracker=\"tracker.det_score_fun.frag_score_fun.dill\",\n",
    "                                                confidence_filter_detections=config[\"confidence_filter_detections\"],\n",
    "                                               confidence_filter_tracks=config[\"confidence_filter_tracks\"],\n",
    "                                                coordinate_scale=config[\"coordinate_scale\"],\n",
    "                                               )\n",
    "            date_string = filename_to_datestring(path)\n",
    "            tracks['video'] = date_string\n",
    "            video_data[path] = (frame_info, detections, tracks)\n",
    "        except ValueError as err: #tritt auf, wenn Video leer ist. In diesem Fall: überspringe video\n",
    "            try:\n",
    "                bad_paths.append(path)\n",
    "                # wir arbeiten später nochmal mit paths, daher müssen das leere löschen, weil sonst\n",
    "                # in video_data kein zugehöriger Value zu Key = file zu finden ist.\n",
    "            except KeyError as err:\n",
    "                continue\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "            raise\n",
    "        # only first vid: break\n",
    "\n",
    "    for bad_path in bad_paths:\n",
    "        paths.remove(bad_path)\n",
    "\n",
    "    #video_data[\"file\"][0] --> frame-info, [1] --> detections, [2] --> tracks\n",
    "    for path in paths:\n",
    "        display_tracking_results(path, video_data[path][0], video_data[path][1], video_data[path][2])\n",
    "\n",
    "    tracks = [video_data[paths[x]][2] for x in range(len(paths))]\n",
    "    tracks = pd.concat(tracks,ignore_index=True)\n",
    "    tracks = tracks.drop(columns=[\"localizerSaliency\", \"beeID\", \"camID\", \"frameIdx\"])\n",
    "\n",
    "    if save_to_csv:\n",
    "        with open(\"tracks.csv\", \"w\") as f:\n",
    "            tracks.to_csv(f)\n",
    "\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a: Create video path list from all videos in videos_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T09:53:00.145666Z",
     "start_time": "2019-03-18T09:53:00.137197Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Einen Iterable speichern, der alle Videos in einem Iterable zur Verfügung stellt\n",
    "# Diesen Iterable können wir dann in der nächsten Zelle mit tqdm schön durchlaufen\n",
    "base_directory = config[\"videos_dir\"]\n",
    "paths = [i for i in os.listdir(base_directory) if i.endswith(\".h264\")]\n",
    "for i in range(len(paths)):\n",
    "    paths[i] = base_directory + paths[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b: Create video path list from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T09:53:07.202945Z",
     "start_time": "2019-03-18T09:53:07.028564Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the test data csv\n",
    "test_data = loadGTD(\"bees_test.csv\")\n",
    "\n",
    "all_videos = []\n",
    "\n",
    "all_paths = pd.DataFrame(glob.glob(os.path.join(config[\"videos_dir\"], '*.h264')), columns=['video'])\n",
    "all_paths['video'] = all_paths['video'].apply(lambda x: filename_to_datestring(x))\n",
    "all_paths.sort_values(['video'])\n",
    "\n",
    "# go through test_data and get all videos between timestamp_in and timestamp_out\n",
    "for index, row in test_data.iterrows():\n",
    "    all_videos += get_videos_between(row['video_start_time'],row['video_end_time'], all_paths)\n",
    "    \n",
    "all_videos = sorted(list(set(all_videos)))\n",
    "paths = [datestring_to_filename(x) for x in all_videos]\n",
    "del all_paths\n",
    "del test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue here"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T10:35:09.468983Z",
     "start_time": "2019-03-15T10:35:09.453016Z"
    }
   },
   "source": [
    "tracks = detect_tracks(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zwischenschritt: Merge all close Tracks of one bee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T09:54:22.640349Z",
     "start_time": "2019-03-18T09:54:22.606339Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN THIS IF TRACKS WHERE ALREADY CALCULATED AND SAVED TO AN .csv\n",
    "# CSV EINLESEN UND SETZEN\n",
    "tracks = pd.read_csv(\"all_tracks.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T09:53:31.144681Z",
     "start_time": "2019-03-18T09:53:30.824202Z"
    },
    "code_folding": [
     0,
     39
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gather_tracks(tracks):\n",
    "    \"\"\"\n",
    "    transform the tracks df to : bee_id, [list of positions (x,y)], [list of timestamps], timestamp_of video\n",
    "    \"\"\"\n",
    "\n",
    "    #  transform tracks df to : bee_id, [list of positions (x,y)], [list of timestamps], timestamp_of video\n",
    "    grouped = tracks.groupby(['bee_id','track_id','video'],  as_index=False)['xpos','ypos','timestamp','zrotation']\n",
    "\n",
    "    tracks_ml = grouped.aggregate(lambda x: list(x))\n",
    "\n",
    "    # we don't need track_id anymore\n",
    "    tracks_ml = tracks_ml.drop('track_id', 1)\n",
    "\n",
    "    # add a column: convert video name to timestamp\n",
    "    tracks_ml['video_start_time'] = tracks_ml['video'].apply(lambda x: string_to_timestamp(x))\n",
    "    \n",
    "    # we don't need video anymore\n",
    "    tracks_ml = tracks_ml.drop('video', 1)\n",
    "\n",
    "    # because aggregated: now multiple timestamps per row: --> rename\n",
    "    tracks_ml = tracks_ml.rename(columns={'timestamp': 'timestamps'})\n",
    "\n",
    "    # calculate start time of track by adding timestamp of track (seconds since start of video)\n",
    "    # to timestamp of video (date)\n",
    "    tracks_ml['track_start_time'] = tracks_ml['video_start_time'] + tracks_ml['timestamps'].apply(lambda x: x[0])\n",
    "    tracks_ml['track_end_time'] = tracks_ml['video_start_time'] + tracks_ml['timestamps'].apply(lambda x: x[-1])\n",
    "    \n",
    "    # convert back to string\n",
    "    tracks_ml['video_start_time'] = tracks_ml['video_start_time'].apply(lambda x: timestamp_to_string(x))\n",
    "    \n",
    "    all_paths = pd.DataFrame(glob.glob(os.path.join(config[\"videos_dir\"], '*.h264')), columns=['video'])\n",
    "    all_paths['video'] = all_paths['video'].apply(lambda x: filename_to_datestring(x))\n",
    "    all_paths.sort_values(['video'])\n",
    "    # get end video\n",
    "    tracks_ml['video_end_time'] =  tracks_ml['track_end_time'].apply(lambda x: timestamp_to_string(x))\n",
    "    tracks_ml['video_end_time'] =  tracks_ml[['video_start_time','video_end_time']].apply(lambda x: get_videos_between(x[0],x[1],all_paths)[-1], axis=1)\n",
    "\n",
    "    return tracks_ml\n",
    "\n",
    "def merge_tracks(tracks_ml, verbose = False):\n",
    "    \"\"\"\n",
    "    in: \n",
    "        tracks_ml: output from gather_tracks(tracks)\n",
    "    out:\n",
    "        same df as in, with merged rows\n",
    "        [bee_id:Float, xpos:[Float], ypos:[Float], zrotation:[Float], timestamps:[Float], video_start_time: String,\n",
    "        video_end_time: String, track_start_time:Float, track_end_time:Float]\n",
    "        \n",
    "    merge tracks of same bee where start and end timestamps are close together\n",
    "    assume there can not be overlapping tracks\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # 1. sort: bee_id, start_time\n",
    "    tracks_ml = tracks_ml.sort_values(['bee_id', 'track_start_time'])\n",
    "\n",
    "    \n",
    "    # first convert to timestamp\n",
    "    tracks_ml['video_start_time'] = tracks_ml['video_start_time'].apply(lambda x: string_to_timestamp(x))\n",
    "    \n",
    "    index = 0\n",
    "    while(True):\n",
    "        row = tracks_ml.iloc[index]\n",
    "        next_row = tracks_ml.iloc[index+1]\n",
    "\n",
    "        # if the tracks are from same bee and the start time of next row is closer then 10s -> merge the rows\n",
    "        # merge rows means, next_row is deleted\n",
    "        if (row['bee_id'] == next_row['bee_id']) and ((next_row['track_start_time'] - row['track_end_time']) < 10):\n",
    "            \n",
    "            if verbose:\n",
    "                print(timestamp_to_string(row['video_start_time']), row['bee_id'], next_row['track_start_time'] - row['track_end_time'])\n",
    "                print(next_row['video_start_time'] - row['video_start_time'])\n",
    "                print(timestamp_to_string(row['track_start_time']),timestamp_to_string(row['track_end_time']),timestamp_to_string(row['video_start_time']),row['video_end_time'])\n",
    "                print(row['timestamps'])\n",
    "                print(row.name)\n",
    "                print(timestamp_to_string(next_row['track_start_time']))\n",
    "                print('----------------------------------')\n",
    "           \n",
    "            # update the timestamps of nextrow\n",
    "            t = next_row['video_start_time'] - row['video_start_time']\n",
    "            timestamps = list( np.array(next_row['timestamps']) + t)\n",
    "\n",
    "            # merge xpos, ypos, timestamps lists\n",
    "            tracks_ml.at[row.name,'xpos'] = row['xpos']+next_row['xpos']\n",
    "            tracks_ml.at[row.name,'ypos'] = row['ypos']+next_row['ypos']\n",
    "            tracks_ml.at[row.name,'timestamps'] = row['timestamps']+timestamps\n",
    "\n",
    "            # update end_time\n",
    "            tracks_ml.at[row.name,'track_end_time'] = next_row['track_end_time']\n",
    "            tracks_ml.at[row.name,'video_end_time'] = next_row['video_end_time']\n",
    "\n",
    "            # delete the merged row (next_row)\n",
    "            tracks_ml = tracks_ml.drop(next_row.name).copy()\n",
    "\n",
    "        else:\n",
    "            index += 1\n",
    "        \n",
    "        if index == len(tracks_ml) - 1:\n",
    "            break\n",
    "            \n",
    "    # convert back to string\n",
    "    tracks_ml['video_start_time'] = tracks_ml['video_start_time'].apply(lambda x: timestamp_to_string(x))\n",
    "            \n",
    "    return tracks_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T10:46:16.201090Z",
     "start_time": "2019-03-18T10:46:15.450919Z"
    }
   },
   "outputs": [],
   "source": [
    "tracks_ml = gather_tracks(tracks)\n",
    "tracks_ml = merge_tracks(tracks_ml)\n",
    "tracks_ml = tracks_ml.sort_values(['video_start_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy of Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T10:46:18.029655Z",
     "start_time": "2019-03-18T10:46:18.013205Z"
    }
   },
   "outputs": [],
   "source": [
    "# read in the test data csv (the manually labeled data)\n",
    "test_data = loadGTD(\"bees_test.csv\")\n",
    "test_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T10:46:18.764439Z",
     "start_time": "2019-03-18T10:46:18.760797Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data_len = len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T10:46:37.019510Z",
     "start_time": "2019-03-18T10:46:36.976329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bee_id and video_start_time correct: 0.67 (70/104)\n",
      "bee_id and video_end_time correct: 0.66 (69/104)\n",
      "bee_ids and both videos correct: 0.60 (62/104)\n"
     ]
    }
   ],
   "source": [
    "# get the total number of tracks where the start_video and bee_id is correct\n",
    "correct_in_video_start = len(pd.merge(tracks_ml,test_data[['bee_id','in_direction','video_start_time']], on=['bee_id','video_start_time'], how='inner'))\n",
    "\n",
    "# get the total number of tracks where the end video and bee_id is correct\n",
    "correct_in_video_end = len(pd.merge(tracks_ml,test_data[['bee_id','out_direction','video_end_time']], on=['bee_id','video_end_time'], how='inner'))\n",
    "\n",
    "# get all tracks where bee_id, video_start_time and video_end_time are the same\n",
    "total_correct = len(pd.merge(tracks_ml,test_data[['bee_id','in_direction','out_direction','video_end_time','video_start_time']], how='inner',on=['bee_id','video_start_time','video_end_time']))\n",
    "\n",
    "print('bee_id and video_start_time correct: %.2f (%d/%d)' % (correct_in_video_start/test_data_len,correct_in_video_start,test_data_len))\n",
    "print('bee_id and video_end_time correct: %.2f (%d/%d)' % (correct_in_video_end/test_data_len,correct_in_video_end,test_data_len))\n",
    "print('bee_ids and both videos correct: %.2f (%d/%d)' % (total_correct/test_data_len,total_correct,test_data_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add labels to tracks data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T10:47:12.850202Z",
     "start_time": "2019-03-18T10:47:12.834471Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get all tracks where bee_id, video_start_time and video_end_time are the same\n",
    "tracks_ml = pd.merge(tracks_ml,test_data,how='inner',on=['bee_id','video_start_time','video_end_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T13:36:52.994103Z",
     "start_time": "2019-03-18T13:36:52.950232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bee_id</th>\n",
       "      <th>xpos</th>\n",
       "      <th>ypos</th>\n",
       "      <th>timestamps</th>\n",
       "      <th>zrotation</th>\n",
       "      <th>video_start_time</th>\n",
       "      <th>track_start_time</th>\n",
       "      <th>track_end_time</th>\n",
       "      <th>video_end_time</th>\n",
       "      <th>in_direction</th>\n",
       "      <th>out_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970.0</td>\n",
       "      <td>[1175.1580028533936, 1275.0042209625246, 1199....</td>\n",
       "      <td>[100.45368194580078, 252.97906684875488, 264.9...</td>\n",
       "      <td>[1.6, 2.3, 2.8, 3.1, 4.0, 4.1, 4.2, 4.3, 4.6, ...</td>\n",
       "      <td>[-1.5437196000000002, 0.18208171, 1.7509313000...</td>\n",
       "      <td>2018-08-19-02-21-37</td>\n",
       "      <td>1.534638e+09</td>\n",
       "      <td>1.534638e+09</td>\n",
       "      <td>2018-08-19-02-22-40</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220.0</td>\n",
       "      <td>[587.6349468231201, 577.2753982543945, 589.496...</td>\n",
       "      <td>[123.45260810852051, 125.9588794708252, 138.67...</td>\n",
       "      <td>[0.4, 14.0, 14.1, 14.2, 14.3, 14.4, 14.5, 14.6...</td>\n",
       "      <td>[-2.787043, 0.020939333, -0.15247042, 0.053603...</td>\n",
       "      <td>2018-08-19-05-25-51</td>\n",
       "      <td>1.534649e+09</td>\n",
       "      <td>1.534649e+09</td>\n",
       "      <td>2018-08-19-05-25-51</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3925.0</td>\n",
       "      <td>[538.5966873168945, 588.3075313568115, 651.012...</td>\n",
       "      <td>[126.37010765075684, 126.80798149108887, 127.0...</td>\n",
       "      <td>[11.9, 12.0, 12.1, 12.2, 12.3, 12.4, 12.5, 12.6]</td>\n",
       "      <td>[-0.48655950000000003, -0.23565856, -0.0598887...</td>\n",
       "      <td>2018-08-19-07-47-52</td>\n",
       "      <td>1.534658e+09</td>\n",
       "      <td>1.534658e+09</td>\n",
       "      <td>2018-08-19-07-47-52</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>388.0</td>\n",
       "      <td>[1375.2675552368164, 1313.4858207702634, 1225....</td>\n",
       "      <td>[239.0948257446289, 238.7294406890869, 237.849...</td>\n",
       "      <td>[0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1]</td>\n",
       "      <td>[2.9390156000000003, 2.9522842999999996, -2.97...</td>\n",
       "      <td>2018-08-19-08-29-06</td>\n",
       "      <td>1.534660e+09</td>\n",
       "      <td>1.534660e+09</td>\n",
       "      <td>2018-08-19-08-29-06</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1066.0</td>\n",
       "      <td>[1413.0752410888672, 1350.3371124267578, 1325....</td>\n",
       "      <td>[251.15822410583496, 238.2443084716797, 188.21...</td>\n",
       "      <td>[1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1, ...</td>\n",
       "      <td>[2.8809676, 3.0900168, -2.7678201000000002, -3...</td>\n",
       "      <td>2018-08-19-09-28-45</td>\n",
       "      <td>1.534664e+09</td>\n",
       "      <td>1.534664e+09</td>\n",
       "      <td>2018-08-19-09-28-45</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bee_id                                               xpos  \\\n",
       "0  1970.0  [1175.1580028533936, 1275.0042209625246, 1199....   \n",
       "1   220.0  [587.6349468231201, 577.2753982543945, 589.496...   \n",
       "2  3925.0  [538.5966873168945, 588.3075313568115, 651.012...   \n",
       "3   388.0  [1375.2675552368164, 1313.4858207702634, 1225....   \n",
       "4  1066.0  [1413.0752410888672, 1350.3371124267578, 1325....   \n",
       "\n",
       "                                                ypos  \\\n",
       "0  [100.45368194580078, 252.97906684875488, 264.9...   \n",
       "1  [123.45260810852051, 125.9588794708252, 138.67...   \n",
       "2  [126.37010765075684, 126.80798149108887, 127.0...   \n",
       "3  [239.0948257446289, 238.7294406890869, 237.849...   \n",
       "4  [251.15822410583496, 238.2443084716797, 188.21...   \n",
       "\n",
       "                                          timestamps  \\\n",
       "0  [1.6, 2.3, 2.8, 3.1, 4.0, 4.1, 4.2, 4.3, 4.6, ...   \n",
       "1  [0.4, 14.0, 14.1, 14.2, 14.3, 14.4, 14.5, 14.6...   \n",
       "2   [11.9, 12.0, 12.1, 12.2, 12.3, 12.4, 12.5, 12.6]   \n",
       "3      [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1]   \n",
       "4  [1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1, ...   \n",
       "\n",
       "                                           zrotation     video_start_time  \\\n",
       "0  [-1.5437196000000002, 0.18208171, 1.7509313000...  2018-08-19-02-21-37   \n",
       "1  [-2.787043, 0.020939333, -0.15247042, 0.053603...  2018-08-19-05-25-51   \n",
       "2  [-0.48655950000000003, -0.23565856, -0.0598887...  2018-08-19-07-47-52   \n",
       "3  [2.9390156000000003, 2.9522842999999996, -2.97...  2018-08-19-08-29-06   \n",
       "4  [2.8809676, 3.0900168, -2.7678201000000002, -3...  2018-08-19-09-28-45   \n",
       "\n",
       "   track_start_time  track_end_time       video_end_time in_direction  \\\n",
       "0      1.534638e+09    1.534638e+09  2018-08-19-02-22-40         left   \n",
       "1      1.534649e+09    1.534649e+09  2018-08-19-05-25-51         left   \n",
       "2      1.534658e+09    1.534658e+09  2018-08-19-07-47-52         left   \n",
       "3      1.534660e+09    1.534660e+09  2018-08-19-08-29-06        right   \n",
       "4      1.534664e+09    1.534664e+09  2018-08-19-09-28-45        right   \n",
       "\n",
       "  out_direction  \n",
       "0          left  \n",
       "1         right  \n",
       "2         right  \n",
       "3          left  \n",
       "4          left  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(tracks_ml))\n",
    "tracks_ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into training and test data\n",
    "mask = np\n",
    "tracks_ml_train = "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T10:00:52.738751Z",
     "start_time": "2019-03-18T10:00:52.391037Z"
    }
   },
   "source": [
    "# we don't use this anymore\n",
    "\n",
    "# we only look at tracks where  in_direction and out_direction are different\n",
    "tracks_ml = tracks_ml[(tracks_ml['in_direction'] != tracks_ml['out_direction'])]\n",
    "\n",
    "# we assign movement based on in_ and out_directoin\n",
    "tracks_ml.loc[(tracks_ml['in_direction'] == 'left') & (tracks_ml['out_direction'] == 'right'),'movement'] = 1\n",
    "tracks_ml.loc[(tracks_ml['in_direction'] == 'right') & (tracks_ml['out_direction'] == 'left'),'movement'] = 0\n",
    "\n",
    "tracks_ml.drop('in_direction', 1, inplace=True)\n",
    "tracks_ml.drop('out_direction', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline-Algorithmen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithmus 1: Baseline - Areas as Decider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T11:34:29.956289Z",
     "start_time": "2019-03-18T11:34:29.899389Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\"\"\" Vorgehen:\n",
    "Für jedes Bienen-Track Paar\n",
    "- Prüfe, wo sich die Biene beim ersten erkannten Erscheinen aufhält\n",
    "    - Ordne die Position in left, right oder middle ein\n",
    "- Prüfe, wo sich die Biene beim letzten erkannten Erscheinen aufhält\n",
    "    - Ordne die Position in left, right oder middle ein\n",
    "Wenn sich Biene in der Mitte befindet, starte neue Routine, die links oder rechts zuordnet\n",
    "Daraus kann nun abgeleitet werden, wo die Biene reingekommen ist und wo sie rausgegangen ist.\n",
    "\"\"\"\n",
    "# param: tracks_ml, s. oben\n",
    "def baseline_alg_classify_bee(tracks_ml):\n",
    "    def get_direction(xpos, zpos):\n",
    "        #Helpers\n",
    "        def is_left(xpos):\n",
    "            return xpos <= config[\"left_leaving_area\"]*config[\"px_x_resolution_vid\"]\n",
    "        def is_right(xpos):\n",
    "            return xpos >= config[\"px_x_resolution_vid\"] - config[\"right_leaving_area\"]*config[\"px_x_resolution_vid\"]\n",
    "        # Routine, wenn Biene in der Mitte\n",
    "        # Betrachte zRotation, das ist die Richtung in die die Biene guckt (in Bogenmaß)\n",
    "        # gebe diese Richtung aus\n",
    "        def middle_classifier(zRotation):\n",
    "            if abs(zRotation) > pi/2:\n",
    "                return \"left\"\n",
    "            else:\n",
    "                return \"right\"\n",
    "            \n",
    "        # Eintrittsseite festlegen\n",
    "        if is_left(xpos):\n",
    "            return \"left\"\n",
    "        elif is_right(xpos):\n",
    "            return \"right\"\n",
    "        else:\n",
    "            return middle_classifier(zpos)\n",
    "        \n",
    "    pred_in_direction = len(tracks_ml) * [None]\n",
    "    pred_out_direction = len(tracks_ml) * [None]\n",
    "    i = 0\n",
    "    for index, row in tracks_ml.iterrows():\n",
    "        pred_in_direction[i] = get_direction(row['xpos'][0], row['zrotation'][0])\n",
    "        pred_out_direction[i]= get_direction(row['xpos'][-1], row['zrotation'][-1])\n",
    "        i += 1\n",
    "    \n",
    "    #remove those with no \n",
    "    return pd.DataFrame({\"pred_in_direction\":pred_in_direction, \"pred_out_direction\":pred_out_direction})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithmus 2: Baseline - zpos as decider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T11:44:25.162071Z",
     "start_time": "2019-03-18T11:44:25.118434Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\"\"\" Vorgehen:\n",
    "Unterschied: Hier wird nicht auf die Position abgestellt, sondern ausschließlich auf die\n",
    "Richtung, in die die Biene schaut\n",
    "\"\"\"\n",
    "# param: tracks_ml, s. oben\n",
    "def baseline_2_alg_classify_bee(tracks_ml):\n",
    "    def get_in_direction(zpos):\n",
    "        # Betrachte zRotation, das ist die Richtung in die die Biene guckt (in Bogenmaß)\n",
    "        # gebe diese Richtung aus\n",
    "        if abs(zpos) > abs(pi/2):\n",
    "            return \"right\"\n",
    "        else:\n",
    "            return \"left\"\n",
    "    def get_out_direction(zpos):\n",
    "        # Betrachte zRotation, das ist die Richtung in die die Biene guckt (in Bogenmaß)\n",
    "        # gebe diese Richtung aus\n",
    "        if abs(zpos) > abs(pi/2):\n",
    "            return \"left\"\n",
    "        else:\n",
    "            return \"right\"\n",
    "        \n",
    "    pred_in_direction = len(tracks_ml) * [None]\n",
    "    pred_out_direction = len(tracks_ml) * [None]\n",
    "    i = 0\n",
    "    for index, row in tracks_ml.iterrows():\n",
    "        pred_in_direction[i] = get_in_direction(row['zrotation'][0])\n",
    "        pred_out_direction[i]= get_out_direction(row['zrotation'][-1])\n",
    "        i += 1\n",
    "    \n",
    "    return pd.DataFrame({\"pred_in_direction\":pred_in_direction, \"pred_out_direction\":pred_out_direction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T13:39:44.728174Z",
     "start_time": "2019-03-14T13:39:44.716229Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\"\"\" Vorgehen:\n",
    "Unterschied: Hier wird nicht auf die Position abgestellt, sondern ausschließlich auf die\n",
    "Richtung, in die die Biene schaut\n",
    "\"\"\"\n",
    "#results = {\"bee_id\":[], \"time_in\":[], \"os_in\":[], \"time_out\":[], \"os_out\":[], \"in_direction\":[], \"out_direction\":[]}\n",
    "# param: tracks_ml, s. oben\n",
    "def baseline_2_alg_classify_bee(tracks_ml):\n",
    "    def get_in_direction(zpos):\n",
    "        # Betrachte zRotation, das ist die Richtung in die die Biene guckt (in Bogenmaß)\n",
    "        # gebe diese Richtung aus\n",
    "        if zpos > abs(pi/2):\n",
    "            return \"right\"\n",
    "        else:\n",
    "            return \"left\"\n",
    "    def get_out_direction(zpos):\n",
    "        # Betrachte zRotation, das ist die Richtung in die die Biene guckt (in Bogenmaß)\n",
    "        # gebe diese Richtung aus\n",
    "        if zpos > abs(pi/2):\n",
    "            return \"left\"\n",
    "        else:\n",
    "            return \"right\"\n",
    "    \n",
    "    # \"bee_id\":[int], \"time_in\":[String], \"os_in\":[Float], \"time_out\":[String],\n",
    "    # \"os_out\":[Float], \"in_direction\":[{\"left\", \"right\"}], \"out_direction\":[{\"left\", \"right\"}]\n",
    "    results = {\"bee_id\":[], \"time_in\":[], \"os_in\":[], \"time_out\":[], \"os_out\":[], \"in_direction\":[],\n",
    "               \"out_direction\":[]}\n",
    "        \n",
    "    for row in tracks_ml.itertuples(index=False):\n",
    "        results[\"bee_id\"].append(row[0])\n",
    "        results[\"time_in\"].append(row[5])\n",
    "        results[\"os_in\"].append(row[-3] - string_to_timestamp(row[5])) #track_start_time - video_start_time\n",
    "        results[\"time_out\"].append(row[-1])\n",
    "        results[\"os_out\"].append(row[-2] - string_to_timestamp(row[-1])) #track_end_time - video_end_time\n",
    "        results[\"in_direction\"].append(get_in_direction(row[4][0]))\n",
    "        results[\"out_direction\"].append(get_out_direction(row[4][-1]))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T13:34:16.089741Z",
     "start_time": "2019-03-18T13:34:16.026672Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def conbine_in_out(y_in, y_out):\n",
    "    \"\"\" convert in_direction, out_direction to ll, lr, rr, rl \"\"\"\n",
    "    \n",
    "    in_label = y_in.copy()\n",
    "    in_label[y_in == 'left'] = 'L'\n",
    "    in_label[y_in == 'right'] = 'R'\n",
    "    \n",
    "    out_label = y_out.copy()\n",
    "    out_label[y_out == 'left'] = 'L'\n",
    "    out_label[y_out == 'right'] = 'R'\n",
    "\n",
    "    return in_label + out_label\n",
    "    \n",
    "\n",
    "def print_classifier_metrics(y, ypred):\n",
    "    \n",
    "        print('Confusion Matrix In-Direction:')\n",
    "        print(pd.DataFrame(confusion_matrix(tracks_ml['in_direction'], ypred['pred_in_direction']), columns=['L','R'], index=['L','R']))\n",
    "        print('Accuracy In-Direction:',accuracy_score(tracks_ml['in_direction'], ypred['pred_in_direction']))\n",
    "        print('\\n')\n",
    "        print('Confusion Matrix Out-Direction:')\n",
    "        print(pd.DataFrame(confusion_matrix(tracks_ml['out_direction'], ypred['pred_out_direction']), columns=['L','R'], index=['L','R']))\n",
    "        print('Accuracy Out-Direction:',accuracy_score(tracks_ml['out_direction'], ypred['pred_out_direction']))\n",
    "        \n",
    "        y_combined = conbine_in_out(y['in_direction'], y['out_direction'])\n",
    "        y_pred_combined = conbine_in_out(ypred['pred_in_direction'], ypred['pred_out_direction'])\n",
    "        print('\\n')\n",
    "        print('Confusion Matrix Combined:')\n",
    "        print(pd.DataFrame(confusion_matrix(y_combined,y_pred_combined, labels=['LL', 'LR', 'RL', 'RR']), columns=['LL', 'LR', 'RL', 'RR'], index=['LL', 'LR', 'RL', 'RR']))\n",
    "        print('Total Accuracy:', accuracy_score(y_combined, y_pred_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T13:34:16.953200Z",
     "start_time": "2019-03-18T13:34:16.889037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix In-Direction:\n",
      "    L   R\n",
      "L  33   7\n",
      "R   8  14\n",
      "Accuracy In-Direction: 0.7580645161290323\n",
      "\n",
      "\n",
      "Confusion Matrix Out-Direction:\n",
      "    L   R\n",
      "L  29   1\n",
      "R   5  27\n",
      "Accuracy Out-Direction: 0.9032258064516129\n",
      "\n",
      "\n",
      "Confusion Matrix Combined:\n",
      "    LL  LR  RL  RR\n",
      "LL  12   1   1   0\n",
      "LR   3  17   1   5\n",
      "RL   4   0  12   0\n",
      "RR   1   3   0   2\n",
      "Total Accuracy: 0.6935483870967742\n"
     ]
    }
   ],
   "source": [
    "results = baseline_alg_classify_bee(tracks_ml)\n",
    "print_classifier_metrics(tracks_ml[['in_direction','out_direction']], results[['pred_in_direction','pred_out_direction']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T13:34:25.948049Z",
     "start_time": "2019-03-18T13:34:25.891626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix In-Direction:\n",
      "    L   R\n",
      "L  37   3\n",
      "R   3  19\n",
      "Accuracy In-Direction: 0.9032258064516129\n",
      "\n",
      "\n",
      "Confusion Matrix Out-Direction:\n",
      "    L   R\n",
      "L  25   5\n",
      "R   5  27\n",
      "Accuracy Out-Direction: 0.8387096774193549\n",
      "\n",
      "\n",
      "Confusion Matrix Combined:\n",
      "    LL  LR  RL  RR\n",
      "LL  10   3   1   0\n",
      "LR   3  21   0   2\n",
      "RL   0   2  14   0\n",
      "RR   0   1   2   3\n",
      "Total Accuracy: 0.7741935483870968\n"
     ]
    }
   ],
   "source": [
    "results = baseline_2_alg_classify_bee(tracks_ml)\n",
    "print_classifier_metrics(tracks_ml[['in_direction','out_direction']], results[['pred_in_direction','pred_out_direction']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmus 3: Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorbereiten Lernvideos, Prüfvideos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Tracks um 180° drehen; Tracks horizontal invertieren; Tracks vertikal invertieren (Funktioniert, abhängig von der Wichtigkeit der Zeit als Feature, vielleicht nicht!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T12:41:18.043523Z",
     "start_time": "2019-03-15T12:41:18.038981Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tracks um 180° drehen\n",
    "track_rotated = tracks_ml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Lernen Logistische Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Alg: Logistische Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Lernen Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Alg Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vergleichsfunktion Algorithmus mit Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T11:01:46.441371Z",
     "start_time": "2019-03-15T11:01:46.361187Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAccuracy():\n",
    "    \"\"\" \n",
    "    Input: bees_test.csv, MachineLearnedData.csv\n",
    "    Output: \"result\" as DataFrame with an overview of compareable bees adn their correct/wrong correctness\n",
    "    \n",
    "    Read in two csv file and store values in DataFrame's. Merge DataFrame's to get exact correctness of \n",
    "    total-, in- and out_direction of bees regarding their time_in and time_out relation. \n",
    "    \"\"\"\n",
    "\n",
    "    # delete existing result.csv file to prevent errors\n",
    "    if (os.path.isfile('./result.csv')):\n",
    "        os.remove(\"result.csv\")\n",
    "\n",
    "    # store data in dataFrame\n",
    "    gtd = loadGTD('bees_test.csv')\n",
    "    mld = pd.read_csv('MachineLearnedData.csv')\n",
    "\n",
    "    # change column name to merge dataFrames\n",
    "    gtd.rename(columns = {'video_start_time':'time_in', 'video_end_time':'time_out'}, inplace=True)\n",
    "\n",
    "    # delete dublications\n",
    "    mld = mld.drop_duplicates(['bee_id', 'time_in', 'time_out'], keep='first')\n",
    "    gtd = gtd.drop_duplicates(['bee_id', 'time_in', 'time_out'], keep='first')\n",
    "\n",
    "    # change DT from float to int to have the same DT like gtd\n",
    "    mld.bee_id = mld.bee_id.astype('int32')\n",
    "\n",
    "    # merge to get 100% correct matches\n",
    "    mergeTotalCorrect = pd.merge(gtd, mld, on=['bee_id', 'time_in', 'time_out', 'in_direction', 'out_direction'], how='inner')\n",
    "    #merge to get in_direction correct\n",
    "    mergeInDirection = pd.merge(gtd, mld, on=['bee_id', 'time_in', 'in_direction'], how='inner')\n",
    "    #merge to get out_direction correct\n",
    "    mergeOutDirection = pd.merge(gtd, mld, on=['bee_id', 'time_out', 'out_direction'], how='inner')\n",
    "    # merge to get comparable bees to get all found bees\n",
    "    mergeableBees = pd.merge(gtd, mld, on=['bee_id', 'time_in', 'time_out'], how='inner')\n",
    "\n",
    "    # iterate mergeableBees for visualization\n",
    "    result = pd.DataFrame()\n",
    "    result['bee_id'] = mergeableBees['bee_id'] \n",
    "    result['in_equals'] = mergeableBees['in_direction_x'] == mergeableBees['in_direction_y']\n",
    "    result['out_equals'] = mergeableBees['out_direction_x'] == mergeableBees['out_direction_y']\n",
    "    #result['movement'] = result['in_equals'].bool() == True and result['out_equals'].bool() == False\n",
    "\n",
    "    # store to result.csv\n",
    "    result.to_csv('result.csv', encoding='utf-8', index=False)\n",
    "\n",
    "    # calculate statitics\n",
    "    inCorrect = round((result['in_equals'].sum()/len(result) * 100), 2)\n",
    "    outCorrect = round((result['out_equals'].sum()/len(result) * 100), 2)\n",
    "    allCorrect = round(((result['in_equals'] == result['out_equals']).sum()/len(result) * 100), 2)\n",
    "    aveCorrect = round(((allCorrect + inCorrect + outCorrect) / 3), 2)\n",
    "\n",
    "    # print statistics\n",
    "    try:\n",
    "        print(len(gtd), 'entries in GroundTruthData.', len(mergeableBees), 'entries compareable in MachineLearnedData: ', round((len(mergeableBees)/len(gtd))*100, 2), '%' )\n",
    "        print(allCorrect, \"% total correctness.\")\n",
    "        print(inCorrect, \"% Ingoing correctness.\")\n",
    "        print(outCorrect, \"% Outgoing correctness.\")\n",
    "        print(aveCorrect, \"% Average correctness.\")\n",
    "        print(\"Accuracy of \",round((len(mergeableBees)/len(gtd))*100*(allCorrect/100),2),\"%.\")\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Nothing to compare!\")\n",
    "\n",
    "    # end compare algorithm\n",
    "    print('\\nCheck result.csv file or hit \\'result\\' for more details.')\n",
    "    print('Use DataFrames for deeper information: \\n\\'mergeTotalCorrect\\',\\'mergeInCorrect\\',\\'mergeOutCorrect\\',\\'mergeableBees\\' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
