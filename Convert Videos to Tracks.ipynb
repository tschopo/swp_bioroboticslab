{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T13:49:53.801070Z",
     "start_time": "2019-03-11T13:49:51.636397Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport bb_behavior\n",
    "%aimport bb_behavior.plot\n",
    "%aimport bb_behavior.tracking\n",
    "%aimport bb_behavior.tracking.pipeline\n",
    "\n",
    "import bb_behavior\n",
    "import bb_behavior.plot\n",
    "import bb_behavior.tracking\n",
    "import bb_behavior.tracking.pipeline\n",
    "\n",
    "from bb_behavior.tracking.pipeline import get_default_pipeline\n",
    "from tqdm import tqdm_notebook # progress bar\n",
    "import math\n",
    "from bb_tracking.data.constants import DETKEY\n",
    "#from bb_tracking.tracking import score_id_sim_v\n",
    "from bb_tracking.tracking import distance_orientations_v, distance_positions_v\n",
    "\n",
    "from bb_behavior.tracking.pipeline import detect_markers_in_video\n",
    "from bb_behavior.tracking.pipeline import track_detections_dataframe\n",
    "from bb_behavior.tracking.pipeline import display_tracking_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T13:49:57.127491Z",
     "start_time": "2019-03-11T13:49:57.106298Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "def filename_to_datestring(filname):\n",
    "    \"\"\"\n",
    "    filename can be path\n",
    "    \"\"\"\n",
    "    return os.path.split(filname)[-1].split('.')[0].split('_')[1]\n",
    "\n",
    "\n",
    "def string_to_timestamp(datestring):\n",
    "    \"\"\" \n",
    "    params\n",
    "        string: format 2018-08-19-01-08-13\n",
    "    output\n",
    "        unix timestamp (float)\n",
    "    \"\"\"\n",
    "    \n",
    "    return time.mktime(time.strptime(datestring, \"%Y-%m-%d-%H-%M-%S\"))\n",
    "\n",
    "def timestamp_to_string(timestamp):\n",
    "    return time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime(timestamp))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T13:49:57.714025Z",
     "start_time": "2019-03-11T13:49:57.685478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../videos/videos_tags/e00_2018-08-19-01-08-13.h264\n",
      "2018-08-19-01-08-13\n",
      "1534633693.0\n",
      "2018-08-19-01-08-13\n"
     ]
    }
   ],
   "source": [
    "paths = glob.glob(os.path.join('../videos/videos_tags/', '*.h264'))\n",
    "datestring = filename_to_datestring(paths[0])\n",
    "timestamp = string_to_timestamp(datestring)\n",
    "string =  timestamp_to_string(timestamp)\n",
    "\n",
    "print(paths[0])\n",
    "print(datestring)\n",
    "print(timestamp)\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T13:44:46.247413Z",
     "start_time": "2019-03-11T13:44:46.242406Z"
    }
   },
   "outputs": [],
   "source": [
    "time.mktime(time.strptime(datestring, \"%Y-%m-%d-%H-%M-%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T13:44:46.869944Z",
     "start_time": "2019-03-11T13:44:46.864597Z"
    }
   },
   "outputs": [],
   "source": [
    "time.localtime(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T11:03:14.763453Z",
     "start_time": "2019-03-11T10:59:50.653136Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "tag_pixel_diameter = 50\n",
    "n_frames = None\n",
    "fps = 10.0\n",
    "progress = \"tqdm_notebook\"\n",
    "tracker = \"../tracker.det_score_fun.frag_score_fun.dill\"\n",
    "confidence_filter_detections = 0.08\n",
    "confidence_filter_tracks = 0.2\n",
    "coordinate_scale = 1.0\n",
    "localizer_threshold=\"0.55\"\n",
    "\n",
    "#1944\n",
    "\n",
    "default_pipeline = get_default_pipeline(localizer_threshold=localizer_threshold)\n",
    "\n",
    "track_dfs = []\n",
    "\n",
    "counter = 0\n",
    "for path in glob.glob(os.path.join('../videos/videos_tags/', '*.h264')):  \n",
    "\n",
    "    print(counter, \": \", path)\n",
    "    \n",
    "    try:\n",
    "\n",
    "        # get the detections\n",
    "        frame_info, detections = detect_markers_in_video(path,\n",
    "                                                decoder_pipeline=default_pipeline,\n",
    "                                                tag_pixel_diameter=tag_pixel_diameter,\n",
    "                                                n_frames=n_frames,\n",
    "                                                fps=fps,\n",
    "                                                progress=progress)\n",
    "\n",
    "        print(len(detections))\n",
    "        # get the tracks                                           \n",
    "        tracks = track_detections_dataframe(detections,\n",
    "                                            tracker=tracker,\n",
    "                                            confidence_filter_detections=confidence_filter_detections,\n",
    "                                            confidence_filter_tracks=confidence_filter_tracks,\n",
    "                                            coordinate_scale=coordinate_scale)\n",
    "        # get date from filename\n",
    "        date_string = os.path.split(path)[-1].split('.')[0].split('_')[1]\n",
    "        timestamp = time.mktime(datetime.datetime.strptime(date_string, \"%Y-%m-%d-%H-%M-%S\").timetuple())\n",
    "\n",
    "        #  transform tracks df to : bee_id, [list of positions (x,y)], [list of timestamps], timestamp_of video\n",
    "        grouped = tracks.groupby('track_id',  as_index=False)['bee_id','xpos','ypos','timestamp']\n",
    "        df = grouped.aggregate(lambda x: list(x))\n",
    "        df = df.drop('track_id', 1)\n",
    "\n",
    "        df['timestamp_video'] = timestamp\n",
    "        df = df.rename(columns={'timestamp': 'timestamps'})\n",
    "\n",
    "        # convert bee_id list to single value\n",
    "        df['bee_id'] = df['bee_id'].apply(lambda x: x[0])\n",
    "\n",
    "        # only appen if note detections?\n",
    "        track_dfs.append(df)\n",
    "\n",
    "        if counter == 4: \n",
    "            break\n",
    "        counter += 1\n",
    "    \n",
    "    except ValueError as err: #tritt auf, wenn Video leer ist. In diesem Fall: überspringe video\n",
    "        print(err)\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        raise\n",
    "    \n",
    "# bind dataframes together\n",
    "tracks = pd.concat(track_dfs,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T12:12:37.154199Z",
     "start_time": "2019-03-11T12:12:37.126537Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge tracks of same bee where start and end timestamps are close together\n",
    "# assume there can not be overlapping tracks\n",
    "# 1. sort: bee_id, start_time\n",
    "\n",
    "# calculate start time of track by adding timestamp of track (seconds since start of video)\n",
    "# to timestamp of video (date)\n",
    "tracks['start_time'] = tracks['timestamp_video'] + tracks['timestamps'].apply(lambda x: x[0])\n",
    "tracks['end_time'] = tracks['timestamp_video'] + tracks['timestamps'].apply(lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T12:12:38.068681Z",
     "start_time": "2019-03-11T12:12:38.063940Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracks3 = tracks.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T12:21:10.354029Z",
     "start_time": "2019-03-11T12:21:10.343389Z"
    }
   },
   "outputs": [],
   "source": [
    "tracks['timestamps'].apply(lambda x: x[-1]) - tracks['timestamps'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T12:21:37.404493Z",
     "start_time": "2019-03-11T12:21:37.391823Z"
    }
   },
   "outputs": [],
   "source": [
    "tracks['end_time'] - tracks['start_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T12:20:48.375346Z",
     "start_time": "2019-03-11T12:20:48.346235Z"
    }
   },
   "outputs": [],
   "source": [
    "tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T16:56:49.012836Z",
     "start_time": "2019-03-07T16:56:48.948221Z"
    }
   },
   "outputs": [],
   "source": [
    "tracks = tracks3.copy()\n",
    "tracks = tracks.sort_values(['bee_id', 'start_time'])\n",
    "\n",
    "index = 0\n",
    "tracks2 = tracks.copy()\n",
    "while(True):\n",
    "    row = tracks.iloc[index]\n",
    "    next_row = tracks.iloc[index+1]\n",
    "    \n",
    "    # if the tracks are from same bee and the start time of next row is closer then 10s -> merge the rows\n",
    "    # merge rows means, next_row is deleted\n",
    "    if row['bee_id'] == next_row['bee_id'] and next_row['start_time'] - row['end_time'] < 10:\n",
    "        print(next_row['start_time'] - row['end_time'], row['bee_id'], next_row['bee_id'])\n",
    "\n",
    "        # update the timestamps of nextrow\n",
    "        t = next_row['start_time'] - row['start_time']\n",
    "        timestamps = list(np.array(next_row['timestamps']) + t)\n",
    "        \n",
    "        tracks.at[row.name,'xpos'] = row['xpos']+next_row['xpos']\n",
    "        tracks.at[row.name,'ypos'] = row['ypos']+next_row['ypos']\n",
    "        tracks.at[row.name,'timestamps'] = row['timestamps']+timestamps\n",
    "        tracks.at[row.name,'end_time'] = next_row['end_time']\n",
    "        \n",
    "        tracks.drop(tracks.index[index+1], inplace=True)\n",
    "\n",
    "    else:\n",
    "        index += 1\n",
    "    \n",
    "    if index == len(tracks) - 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T16:57:16.392268Z",
     "start_time": "2019-03-07T16:57:16.381530Z"
    }
   },
   "outputs": [],
   "source": [
    "tracks.iloc[0][\"timestamps\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T16:57:51.814496Z",
     "start_time": "2019-03-07T16:57:51.772192Z"
    }
   },
   "outputs": [],
   "source": [
    "tracks = tracks3.copy()\n",
    "tracks = tracks.sort_values(['bee_id', 'start_time'])\n",
    "for index, rows in tracks.iterrows():\n",
    "    row = tracks.iloc[index]\n",
    "    next_row = tracks.iloc[index+1]\n",
    "    print(next_row['start_time'] - row['end_time'], row['bee_id'], next_row['bee_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T16:02:11.305591Z",
     "start_time": "2019-03-07T16:02:11.264647Z"
    }
   },
   "outputs": [],
   "source": [
    "tracks3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:54:36.859111Z",
     "start_time": "2019-03-07T15:54:36.808602Z"
    }
   },
   "outputs": [],
   "source": [
    "tracks2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:38:01.102291Z",
     "start_time": "2019-03-07T15:38:01.053333Z"
    }
   },
   "outputs": [],
   "source": [
    "tracks2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:04:06.280776Z",
     "start_time": "2019-03-07T14:04:06.272034Z"
    }
   },
   "outputs": [],
   "source": [
    "list(np.array([1,2,3,4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:07:03.665652Z",
     "start_time": "2019-03-07T14:07:03.654029Z"
    }
   },
   "outputs": [],
   "source": [
    "tracks.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T13:47:14.112413Z",
     "start_time": "2019-03-07T13:47:14.099296Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T13:47:23.088561Z",
     "start_time": "2019-03-07T13:47:23.057232Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T16:47:45.182494Z",
     "start_time": "2019-03-07T16:46:43.768889Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "#e00_2018-08-19-02-20-55\n",
    "\n",
    "tag_pixel_diameter = 50\n",
    "n_frames = None\n",
    "fps = 10.0\n",
    "progress = \"tqdm_notebook\"\n",
    "tracker = \"../tracker.det_score_fun.frag_score_fun.dill\"\n",
    "confidence_filter_detections = 0.08 # 0.08\n",
    "confidence_filter_tracks = 0.2 #.2\n",
    "coordinate_scale = 1.0\n",
    "localizer_threshold=\"0.50\" # 50\n",
    "\n",
    "#1944\n",
    "\n",
    "\n",
    "default_pipeline = get_default_pipeline(localizer_threshold=localizer_threshold)\n",
    "\n",
    "track_dfs = []\n",
    "counter = 0\n",
    "for path in ['../videos/videos_tags/e00_2018-08-19-01-08-13.h264']:  \n",
    "\n",
    "    print(counter, \": \", path)\n",
    "    \n",
    "    try:\n",
    "\n",
    "        # get the detections\n",
    "        frame_info, detections = detect_markers_in_video(path,\n",
    "                                                decoder_pipeline=default_pipeline,\n",
    "                                                tag_pixel_diameter=tag_pixel_diameter,\n",
    "                                                n_frames=n_frames,\n",
    "                                                fps=fps,\n",
    "                                                progress=progress)\n",
    "\n",
    "        print(len(detections))\n",
    "        # get the tracks                                           \n",
    "        tracks = track_detections_dataframe(detections,\n",
    "                                            tracker=tracker,\n",
    "                                            confidence_filter_detections=confidence_filter_detections,\n",
    "                                            confidence_filter_tracks=confidence_filter_tracks,\n",
    "                                            coordinate_scale=coordinate_scale)\n",
    "        \n",
    "        display_tracking_results(path, frame_info, detections, tracks)\n",
    "\n",
    "    \n",
    "    except ValueError as err: #tritt auf, wenn Video leer ist. In diesem Fall: überspringe video\n",
    "        print(err)\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
