{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:17:26.745511Z",
     "start_time": "2019-03-13T16:17:26.738816Z"
    }
   },
   "outputs": [],
   "source": [
    "%env KERAS_BACKEND=theano\n",
    "%env THEANO_FLAGS=floatX=float32,device=cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:17:31.790380Z",
     "start_time": "2019-03-13T16:17:27.089812Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport bb_behavior\n",
    "%aimport bb_behavior.plot\n",
    "%aimport bb_behavior.tracking\n",
    "%aimport bb_behavior.tracking.pipeline\n",
    "\n",
    "import bb_behavior\n",
    "import bb_behavior.plot\n",
    "import bb_behavior.tracking\n",
    "import bb_behavior.tracking.pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:17:49.916071Z",
     "start_time": "2019-03-13T16:17:32.592971Z"
    }
   },
   "outputs": [],
   "source": [
    "from bb_behavior.tracking.pipeline import get_default_pipeline\n",
    "default_pipeline = None\n",
    "default_pipeline = get_default_pipeline(localizer_threshold=\"0.50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:17:49.939033Z",
     "start_time": "2019-03-13T16:17:49.919515Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook # progress bar\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from bb_tracking.data.constants import DETKEY\n",
    "#from bb_tracking.tracking import score_id_sim_v\n",
    "from bb_tracking.tracking import distance_orientations_v, distance_positions_v\n",
    "\n",
    "from bb_behavior.tracking.pipeline import detect_markers_in_video\n",
    "from bb_behavior.tracking.pipeline import track_detections_dataframe\n",
    "from bb_behavior.tracking.pipeline import display_tracking_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:17:49.946600Z",
     "start_time": "2019-03-13T16:17:49.941172Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "def filename_to_datestring(filname):\n",
    "    \"\"\"\n",
    "    filename can be path\n",
    "    \"\"\"\n",
    "    return os.path.split(filname)[-1].split('.')[0].split('_')[1]\n",
    "\n",
    "\n",
    "def string_to_timestamp(datestring):\n",
    "    \"\"\" \n",
    "    params\n",
    "        string: format 2018-08-19-01-08-13\n",
    "    output\n",
    "        unix timestamp (float)\n",
    "    \"\"\"\n",
    "    \n",
    "    return time.mktime(time.strptime(datestring, \"%Y-%m-%d-%H-%M-%S\"))\n",
    "\n",
    "def timestamp_to_string(timestamp):\n",
    "    return time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime(timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:17:49.958986Z",
     "start_time": "2019-03-13T16:17:49.951100Z"
    }
   },
   "outputs": [],
   "source": [
    "config = dict(tag_pixel_diameter=50,\n",
    "              n_frames=None,\n",
    "              confidence_filter_detections=0.08,\n",
    "              confidence_filter_tracks=0.20,\n",
    "              coordinate_scale=1.0,\n",
    "              start_time=None,\n",
    "              fps=10.0,\n",
    "              cam_id=0,\n",
    "              left_leaving_area = 0.3, # Prozente vom Bildschirmrand, zB. bei 1000px und 0.15 -> 0-150px\n",
    "              right_leaving_area = 0.3,\n",
    "              px_x_resolution_vid = 1944,\n",
    "              videos_dir = \"../videos/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:17:52.627067Z",
     "start_time": "2019-03-13T16:17:52.618520Z"
    }
   },
   "outputs": [],
   "source": [
    "# Einen Iterable speichern, der alle Videos in einem Iterable zur Verfügung stellt\n",
    "# Diesen Iterable können wir dann in der nächsten Zelle mit tqdm schön durchlaufen\n",
    "# nicht sehr performant --> O(n)\n",
    "import os\n",
    "base_directory = config[\"videos_dir\"]\n",
    "paths = [i for i in os.listdir(base_directory) if i.endswith(\".h264\")]\n",
    "for i in range(len(paths)):\n",
    "    paths[i] = base_directory + paths[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:18:24.345046Z",
     "start_time": "2019-03-13T16:17:54.102630Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Hier passiert das eigentliche Tracken und speichern der Ergebnisse:\n",
    "num_processed_videos = 0\n",
    "video_data = dict()\n",
    "frame_info = None\n",
    "detections = None\n",
    "bad_paths = []\n",
    "\n",
    "for path in tqdm_notebook(paths):\n",
    "    start_time = config[\"start_time\"]\n",
    "    cam_id = config[\"cam_id\"]\n",
    "    try:\n",
    "        num_processed_videos += 1\n",
    "\n",
    "        frame_info, detections = detect_markers_in_video(path,\n",
    "                                                      decoder_pipeline=default_pipeline,#pipeline=pipelines(),\n",
    "                                                     tag_pixel_diameter=config[\"tag_pixel_diameter\"],\n",
    "                                                      n_frames=config[\"n_frames\"],\n",
    "                                                      fps=config[\"fps\"],\n",
    "                                                     progress=\"tqdm_notebook\"\n",
    "                                            )\n",
    "        # Sonst würden keine Tracks erkannt werden -> Fehlermeldung\n",
    "        if len(detections[detections['confidence']>=config[\"confidence_filter_detections\"]]) == 0:\n",
    "            continue\n",
    "        tracks = track_detections_dataframe(detections,\n",
    "                                            tracker=\"tracker.det_score_fun.frag_score_fun.dill\",\n",
    "                                            confidence_filter_detections=config[\"confidence_filter_detections\"],\n",
    "                                           confidence_filter_tracks=config[\"confidence_filter_tracks\"],\n",
    "                                            coordinate_scale=config[\"coordinate_scale\"],\n",
    "                                           )\n",
    "        date_string = filename_to_datestring(path)\n",
    "        tracks['video'] = date_string\n",
    "        video_data[path] = (frame_info, detections, tracks)\n",
    "    except ValueError as err: #tritt auf, wenn Video leer ist. In diesem Fall: überspringe video\n",
    "        try:\n",
    "            bad_paths.append(path)\n",
    "            # wir arbeiten später nochmal mit paths, daher müssen das leere löschen, weil sonst\n",
    "            # in video_data kein zugehöriger Value zu Key = file zu finden ist.\n",
    "        except KeyError as err:\n",
    "            continue\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        raise\n",
    "    # only first vid: break\n",
    "\n",
    "for bad_path in bad_paths:\n",
    "    paths.remove(bad_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:16:46.410184Z",
     "start_time": "2019-03-13T15:16:43.432137Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#video_data[\"file\"][0] --> frame-info, [1] --> detections, [2] --> tracks\n",
    "for path in paths:\n",
    "    display_tracking_results(path, video_data[path][0], video_data[path][1], video_data[path][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify data to default for all Algorithms / Save detection to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:18:28.660496Z",
     "start_time": "2019-03-13T16:18:28.650472Z"
    }
   },
   "outputs": [],
   "source": [
    "tracks = [video_data[paths[x]][2] for x in range(len(paths))]\n",
    "tracks = pd.concat(tracks,ignore_index=True)\n",
    "tracks = tracks.drop(columns=[\"localizerSaliency\", \"beeID\", \"camID\", \"frameIdx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:18:29.099753Z",
     "start_time": "2019-03-13T16:18:29.091488Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"tracks.csv\", \"w\") as f:\n",
    "    tracks.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:18:29.652117Z",
     "start_time": "2019-03-13T16:18:29.614257Z"
    }
   },
   "outputs": [],
   "source": [
    "tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T17:43:24.598079Z",
     "start_time": "2019-03-13T17:43:24.591138Z"
    }
   },
   "outputs": [],
   "source": [
    "# ERGEBNIS-DICT, kann mit pd.DataFrame(data=bee_moves) in DataFrame gewandelt werden\n",
    "# \"bee_id\":[int], \"time_in\":[String], \"os_in\":[Float], \"time_out\":[String],\n",
    "# \"os_out\":[Float], \"in_direction\":[{\"left\", \"right\"}], \"out_direction\":[{\"left\", \"right\"}]\n",
    "results = {\"bee_id\":[], \"time_in\":[], \"os_in\":[], \"time_out\":[], \"os_out\":[], \"in_direction\":[], \"out_direction\":[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hilfsfunktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:18:41.996750Z",
     "start_time": "2019-03-13T16:18:41.989291Z"
    }
   },
   "outputs": [],
   "source": [
    "# get all videos between timestamp_in and timestamp_out\n",
    "def get_videos_between(timestamp_in, timestamp_out):\n",
    "    \"\"\" returns all video between timestamp_in and timestamp out (inclusive) \"\"\"\n",
    "    \n",
    "    all_paths = pd.DataFrame(glob.glob(os.path.join(config[\"videos_dir\"], '*.h264')), columns=['video'])\n",
    "    all_paths['video'] = all_paths['video'].apply(lambda x: filename_to_datestring(x))\n",
    "    all_paths.sort_values(['video'])\n",
    "    all_paths.head()\n",
    "    \n",
    "    mask = (all_paths['video'] >= timestamp_in) & (all_paths['video'] <= timestamp_out)\n",
    "    return list(all_paths[mask]['video'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zwischenschritt: Merge all close Tracks of one bee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:18:48.740688Z",
     "start_time": "2019-03-13T16:18:48.722008Z"
    }
   },
   "outputs": [],
   "source": [
    "def gather_tracks(tracks):\n",
    "    \"\"\"\n",
    "    transform the tracks df to : bee_id, xpos, ypos, zrotation, timestamps, video_start_time, video_end_time, track_start_time\n",
    "    \"\"\"\n",
    "\n",
    "    #  transform tracks df to : bee_id, [list of positions (x,y)], [list of timestamps], timestamp_of video\n",
    "    grouped = tracks.groupby(['bee_id','track_id','video'],  as_index=False)['xpos','ypos','timestamp','zrotation']\n",
    "\n",
    "    tracks_ml = grouped.aggregate(lambda x: list(x))\n",
    "\n",
    "    # we don't need track_id anymore\n",
    "    tracks_ml = tracks_ml.drop('track_id', 1)\n",
    "\n",
    "    # add a column: convert video name to timestamp\n",
    "    tracks_ml['video_start_time'] = tracks_ml['video'].apply(lambda x: string_to_timestamp(x))\n",
    "    \n",
    "    # we don't need track_id anymore\n",
    "    tracks_ml = tracks_ml.drop('video', 1)\n",
    "\n",
    "    # because aggregated: now multiple timestamps per row\n",
    "    tracks_ml = tracks_ml.rename(columns={'timestamp': 'timestamps'})\n",
    "\n",
    "    # calculate start time of track by adding timestamp of track (seconds since start of video)\n",
    "    # to timestamp of video (date)\n",
    "    tracks_ml['track_start_time'] = tracks_ml['video_start_time'] + tracks_ml['timestamps'].apply(lambda x: x[0])\n",
    "    tracks_ml['track_end_time'] = tracks_ml['video_start_time'] + tracks_ml['timestamps'].apply(lambda x: x[-1])\n",
    "    \n",
    "    # convert back to string\n",
    "    tracks_ml['video_start_time'] = tracks_ml['video_start_time'].apply(lambda x: timestamp_to_string(x))\n",
    "    \n",
    "    # get end video\n",
    "    \n",
    "    tracks_ml['video_end_time'] =  tracks_ml['track_end_time'].apply(lambda x: timestamp_to_string(x))\n",
    "    \n",
    "    tracks_ml['video_end_time'] =  tracks_ml[['video_start_time','video_end_time']].apply(lambda x: get_videos_between(x[0],x[1])[-1], axis=1)\n",
    "        \n",
    "    return tracks_ml\n",
    "\n",
    "def merge_tracks(tracks_ml, verbose = False):\n",
    "    \"\"\"\n",
    "    in: \n",
    "        tracks_ml: output from gather_tracks(tracks)\n",
    "    out:\n",
    "        same df as in, with merged rows\n",
    "        \n",
    "    merge tracks of same bee where start and end timestamps are close together\n",
    "    assume there can not be overlapping tracks\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. sort: bee_id, start_time\n",
    "    tracks_ml = tracks_ml.sort_values(['bee_id', 'track_start_time'])\n",
    "    \n",
    "    # first convert to timestamp\n",
    "    tracks_ml['video_start_time'] = tracks_ml['video_start_time'].apply(lambda x: string_to_timestamp(x))\n",
    "    \n",
    "    index = 0\n",
    "    while(True):\n",
    "        row = tracks_ml.iloc[index]\n",
    "        next_row = tracks_ml.iloc[index+1]\n",
    "\n",
    "        # if the tracks are from same bee and the start time of next row is closer then 10s -> merge the rows\n",
    "        # merge rows means, next_row is deleted\n",
    "        if (row['bee_id'] == next_row['bee_id']) and ((next_row['track_start_time'] - row['track_end_time']) < 10):\n",
    "            if verbose:\n",
    "                print(next_row['track_start_time'] - row['track_end_time'])\n",
    "\n",
    "            # update the timestamps of nextrow\n",
    "            t = next_row['video_start_time'] - row['video_start_time']\n",
    "            timestamps = list(np.array(next_row['timestamps']) + t)\n",
    "\n",
    "            # merge xpos, ypos, timestamps lists\n",
    "            tracks_ml.at[row.name,'xpos'] = row['xpos']+next_row['xpos']\n",
    "            tracks_ml.at[row.name,'ypos'] = row['ypos']+next_row['ypos']\n",
    "            tracks_ml.at[row.name,'timestamps'] = row['timestamps']+timestamps\n",
    "\n",
    "            # update end_time\n",
    "            tracks_ml.at[row.name,'track_end_time'] = next_row['track_end_time']\n",
    "\n",
    "            # delete the merged row (next_row)\n",
    "            tracks_ml.drop(tracks_ml.index[index+1], inplace=True)\n",
    "\n",
    "        else:\n",
    "            index += 1\n",
    "        \n",
    "        if index == len(tracks_ml) - 1:\n",
    "            break\n",
    "            \n",
    "    # convert back to string\n",
    "    tracks_ml['video_start_time'] = tracks_ml['video_start_time'].apply(lambda x: timestamp_to_string(x))\n",
    "            \n",
    "    return tracks_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T16:18:50.146284Z",
     "start_time": "2019-03-13T16:18:50.088965Z"
    }
   },
   "outputs": [],
   "source": [
    "tracks_ml = gather_tracks(tracks)\n",
    "tracks_ml = merge_tracks(tracks_ml)\n",
    "tracks_ml = tracks_ml.sort_values(['video_start_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T17:30:13.455256Z",
     "start_time": "2019-03-13T17:30:13.431642Z"
    }
   },
   "outputs": [],
   "source": [
    "tracks_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmus 1: Baseline - Areas as Decider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T17:34:27.148453Z",
     "start_time": "2019-03-13T17:34:27.136003Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\"\"\" Vorgehen:\n",
    "Für jedes Bienen-Track Paar\n",
    "- Prüfe, wo sich die Biene beim ersten erkannten Erscheinen aufhält\n",
    "    - Ordne die Position in left, right oder middle ein\n",
    "- Prüfe, wo sich die Biene beim letzten erkannten Erscheinen aufhält\n",
    "    - Ordne die Position in left, right oder middle ein\n",
    "Wenn sich Biene in der Mitte befindet, starte neue Routine, die links oder rechts zuordnet\n",
    "Daraus kann nun abgeleitet werden, wo die Biene reingekommen ist und wo sie rausgegangen ist.\n",
    "\"\"\"\n",
    "#results = {\"bee_id\":[], \"time_in\":[], \"os_in\":[], \"time_out\":[], \"os_out\":[], \"in_direction\":[], \"out_direction\":[]}\n",
    "# param: tracks_ml, s. oben\n",
    "def baseline_alg_classify_bee():\n",
    "    def get_direction(xpos, zpos):\n",
    "        #Helpers\n",
    "        def is_left(xpos):\n",
    "            return xpos <= config[\"left_leaving_area\"]*config[\"px_x_resolution_vid\"]\n",
    "        def is_right(xpos):\n",
    "            return xpos >= config[\"px_x_resolution_vid\"] - config[\"right_leaving_area\"]*config[\"px_x_resolution_vid\"]\n",
    "        # Routine, wenn Biene in der Mitte\n",
    "        # Betrachte zRotation, das ist die Richtung in die die Biene guckt (in Bogenmaß)\n",
    "        # gebe diese Richtung aus\n",
    "        def middle_classifier(zRotation):\n",
    "            if zRotation > abs(pi/2):\n",
    "                return \"left\"\n",
    "            else:\n",
    "                return \"right\"\n",
    "            \n",
    "        # Eintrittsseite festlegen\n",
    "        if is_left(xpos):\n",
    "            return \"left\"\n",
    "        elif is_right(xpos):\n",
    "            return \"right\"\n",
    "        else:\n",
    "            return middle_classifier(zpos)\n",
    "        \n",
    "    for row in tracks_ml.itertuples(index=False):\n",
    "        results[\"bee_id\"].append(row[0])\n",
    "        results[\"time_in\"].append(row[5])\n",
    "        results[\"os_in\"].append(row[-3] - string_to_timestamp(row[5])) #track_start_time - video_start_time\n",
    "        results[\"time_out\"].append(row[-1])\n",
    "        results[\"os_out\"].append(row[-2] - string_to_timestamp(row[-1])) #track_end_time - video_end_time\n",
    "        results[\"in_direction\"].append(get_direction(row[1][0], row[4][0]))\n",
    "        results[\"out_direction\"].append(get_direction(row[1][-1], row[4][-1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T17:34:27.644077Z",
     "start_time": "2019-03-13T17:34:27.625650Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ausgeben\n",
    "baseline_alg_classify_bee()\n",
    "ergebnis = pd.DataFrame(data=results)\n",
    "ergebnis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmus 2: Baseline - zpos as decider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T17:43:33.383135Z",
     "start_time": "2019-03-13T17:43:33.372279Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\"\"\" Vorgehen:\n",
    "Für jedes Bienen-Track Paar\n",
    "- Prüfe, wo sich die Biene beim ersten erkannten Erscheinen aufhält\n",
    "    - Ordne die Position in left, right oder middle ein\n",
    "- Prüfe, wo sich die Biene beim letzten erkannten Erscheinen aufhält\n",
    "    - Ordne die Position in left, right oder middle ein\n",
    "Wenn sich Biene in der Mitte befindet, starte neue Routine, die links oder rechts zuordnet\n",
    "Daraus kann nun abgeleitet werden, wo die Biene reingekommen ist und wo sie rausgegangen ist.\n",
    "\"\"\"\n",
    "#results = {\"bee_id\":[], \"time_in\":[], \"os_in\":[], \"time_out\":[], \"os_out\":[], \"in_direction\":[], \"out_direction\":[]}\n",
    "# param: tracks_ml, s. oben\n",
    "def baseline_2_alg_classify_bee():\n",
    "    def get_in_direction(zpos):\n",
    "        # Betrachte zRotation, das ist die Richtung in die die Biene guckt (in Bogenmaß)\n",
    "        # gebe diese Richtung aus\n",
    "        if zpos > abs(pi/2):\n",
    "            return \"right\"\n",
    "        else:\n",
    "            return \"left\"\n",
    "    def get_out_direction(zpos):\n",
    "        # Betrachte zRotation, das ist die Richtung in die die Biene guckt (in Bogenmaß)\n",
    "        # gebe diese Richtung aus\n",
    "        if zpos > abs(pi/2):\n",
    "            return \"left\"\n",
    "        else:\n",
    "            return \"right\"\n",
    "        \n",
    "    for row in tracks_ml.itertuples(index=False):\n",
    "        results[\"bee_id\"].append(row[0])\n",
    "        results[\"time_in\"].append(row[5])\n",
    "        results[\"os_in\"].append(row[-3] - string_to_timestamp(row[5])) #track_start_time - video_start_time\n",
    "        results[\"time_out\"].append(row[-1])\n",
    "        results[\"os_out\"].append(row[-2] - string_to_timestamp(row[-1])) #track_end_time - video_end_time\n",
    "        results[\"in_direction\"].append(get_in_direction(row[4][0]))\n",
    "        results[\"out_direction\"].append(get_out_direction(row[4][-1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T17:43:33.788846Z",
     "start_time": "2019-03-13T17:43:33.772929Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ausgeben\n",
    "baseline_2_alg_classify_bee()\n",
    "ergebnis = pd.DataFrame(data=results)\n",
    "ergebnis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all videos from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T15:14:29.883766Z",
     "start_time": "2019-03-13T15:14:29.595136Z"
    }
   },
   "outputs": [],
   "source": [
    "# read in the test data csv\n",
    "test_data = pd.read_csv('bees_test.csv')\n",
    "\n",
    "# convert the full filenames to string timestamps, and sort by timestamp_in\n",
    "test_data['video'] = test_data['video'].apply(lambda x: filename_to_datestring(x))\n",
    "test_data['timestamp_in'] = test_data['timestamp_in'].apply(lambda x: filename_to_datestring(x))\n",
    "test_data['timestamp_out'] = test_data['timestamp_out'].apply(lambda x: filename_to_datestring(x))\n",
    "test_data.sort_values(['timestamp_in'])\n",
    "\n",
    "test_data.head()\n",
    "\n",
    "all_videos = []\n",
    "\n",
    "# go through test_data and get all videos between timestamp_in and timestamp_out\n",
    "for index, row in test_data.iterrows():\n",
    "    \n",
    "    all_videos += get_videos_between(row['timestamp_in'],row['timestamp_out'])\n",
    "    \n",
    "all_videos = list(set(all_videos))\n",
    "len(all_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vergleichsfunktion Algorithmus mit Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T16:40:52.696458Z",
     "start_time": "2019-03-07T16:40:52.688866Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
