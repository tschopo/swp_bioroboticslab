{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:12:38.159564Z",
     "start_time": "2019-03-19T10:12:38.152072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=theano\n",
      "env: THEANO_FLAGS=floatX=float32,device=cpu\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND=theano\n",
    "%env THEANO_FLAGS=floatX=float32,device=cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:12:47.256932Z",
     "start_time": "2019-03-19T10:12:38.585018Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport bb_behavior\n",
    "%aimport bb_behavior.plot\n",
    "%aimport bb_behavior.tracking\n",
    "%aimport bb_behavior.tracking.pipeline\n",
    "\n",
    "import bb_behavior\n",
    "import bb_behavior.plot\n",
    "import bb_behavior.tracking\n",
    "import bb_behavior.tracking.pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:12:47.286892Z",
     "start_time": "2019-03-19T10:12:47.261659Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook # progress bar\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from bb_tracking.data.constants import DETKEY\n",
    "#from bb_tracking.tracking import score_id_sim_v\n",
    "from bb_tracking.tracking import distance_orientations_v, distance_positions_v\n",
    "\n",
    "from bb_behavior.tracking.pipeline import detect_markers_in_video\n",
    "from bb_behavior.tracking.pipeline import track_detections_dataframe\n",
    "from bb_behavior.tracking.pipeline import display_tracking_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:13:13.122227Z",
     "start_time": "2019-03-19T10:12:47.290015Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ronnyruhe/.local/lib/python3.7/site-packages/keras/backend/theano_backend.py:1032: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode='max')\n",
      "/Users/ronnyruhe/.local/lib/python3.7/site-packages/keras/backend/theano_backend.py:1032: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode='max')\n",
      "/Users/ronnyruhe/.local/lib/python3.7/site-packages/keras/backend/theano_backend.py:1032: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode='max')\n"
     ]
    }
   ],
   "source": [
    "from bb_behavior.tracking.pipeline import get_default_pipeline\n",
    "default_pipeline = None\n",
    "default_pipeline = get_default_pipeline(localizer_threshold=\"0.50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:13:13.138389Z",
     "start_time": "2019-03-19T10:13:13.126780Z"
    },
    "code_folding": [
     7
    ]
   },
   "outputs": [],
   "source": [
    "# Hilfsfunktionen\n",
    "def filename_to_datestring(filname):\n",
    "    \"\"\"\n",
    "    filename can be path\n",
    "    \"\"\"\n",
    "    return os.path.split(filname)[-1].split('.')[0].split('_')[1]\n",
    "\n",
    "def datestring_to_filename(datestring, prefix=\"e00_\"):\n",
    "    return config[\"videos_dir\"] + prefix + datestring + \".h264\"\n",
    "\n",
    "def string_to_timestamp(datestring):\n",
    "    \"\"\" \n",
    "    params\n",
    "        string: format 2018-08-19-01-08-13\n",
    "    output\n",
    "        unix timestamp (float)\n",
    "    \"\"\"\n",
    "    \n",
    "    return time.mktime(time.strptime(datestring, \"%Y-%m-%d-%H-%M-%S\"))\n",
    "\n",
    "def timestamp_to_string(timestamp):\n",
    "    return time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime(timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:13:23.766901Z",
     "start_time": "2019-03-19T10:13:23.755040Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# get all videos between timestamp_in and timestamp_out\n",
    "def get_videos_between(timestamp_in, timestamp_out, all_paths):\n",
    "    \"\"\" returns all video between timestamp_in and timestamp out (inclusive) \"\"\"\n",
    "    \n",
    "    mask = (all_paths['video'] >= timestamp_in) & (all_paths['video'] <= timestamp_out)\n",
    "    return list(all_paths[mask]['video'])\n",
    "\n",
    "def loadGTD(path):\n",
    "    # read in the test data csv\n",
    "    test_data = pd.read_csv(path)\n",
    "\n",
    "    # convert the full filenames to string timestamps, and sort by timestamp_in\n",
    "    test_data['video'] = test_data['video'].apply(lambda x: filename_to_datestring(x))\n",
    "    test_data['video_start_time'] = test_data['timestamp_in'].apply(lambda x: filename_to_datestring(x))\n",
    "    test_data['video_end_time'] = test_data['timestamp_out'].apply(lambda x: filename_to_datestring(x))\n",
    "    test_data.sort_values(['video_start_time'], inplace=True)\n",
    "\n",
    "    test_data.drop('timestamp_in', 1, inplace=True)\n",
    "    test_data.drop('timestamp_out', 1, inplace=True)\n",
    "    test_data.drop('video', 1, inplace=True)\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:13:29.205427Z",
     "start_time": "2019-03-19T10:13:29.135236Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = loadGTD(\"bees_test.csv\")\n",
    "#tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:13:31.140814Z",
     "start_time": "2019-03-19T10:13:31.133114Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "config = dict(tag_pixel_diameter=50,\n",
    "              n_frames=None,\n",
    "              confidence_filter_detections=0.08,\n",
    "              confidence_filter_tracks=0.20,\n",
    "              coordinate_scale=1.0,\n",
    "              start_time=None,\n",
    "              fps=10.0,\n",
    "              cam_id=0,\n",
    "              left_leaving_area = 0.3, # Prozente vom Bildschirmrand, zB. bei 1000px und 0.15 -> 0-150px\n",
    "              right_leaving_area = 0.3,\n",
    "              px_x_resolution_vid = 1944,\n",
    "              videos_dir = \"../videos/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:13:32.977405Z",
     "start_time": "2019-03-19T10:13:32.957476Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def detect_tracks(paths, save_to_csv = False):\n",
    "    # Hier passiert das eigentliche Tracken und speichern der Ergebnisse:\n",
    "    num_processed_videos = 0\n",
    "    video_data = dict()\n",
    "    frame_info = None\n",
    "    detections = None\n",
    "    bad_paths = []\n",
    "\n",
    "    for path in tqdm_notebook(paths):\n",
    "        start_time = config[\"start_time\"]\n",
    "        cam_id = config[\"cam_id\"]\n",
    "        try:\n",
    "            num_processed_videos += 1\n",
    "\n",
    "            frame_info, detections = detect_markers_in_video(path,\n",
    "                                                          decoder_pipeline=default_pipeline,#pipeline=pipelines(),\n",
    "                                                         tag_pixel_diameter=config[\"tag_pixel_diameter\"],\n",
    "                                                          n_frames=config[\"n_frames\"],\n",
    "                                                          fps=config[\"fps\"],\n",
    "                                                         progress=\"tqdm_notebook\"\n",
    "                                                )\n",
    "            # Sonst würden keine Tracks erkannt werden -> Fehlermeldung\n",
    "            if len(detections[detections['confidence']>=config[\"confidence_filter_detections\"]]) == 0:\n",
    "                continue\n",
    "            tracks = track_detections_dataframe(detections,\n",
    "                                                tracker=\"tracker.det_score_fun.frag_score_fun.dill\",\n",
    "                                                confidence_filter_detections=config[\"confidence_filter_detections\"],\n",
    "                                               confidence_filter_tracks=config[\"confidence_filter_tracks\"],\n",
    "                                                coordinate_scale=config[\"coordinate_scale\"],\n",
    "                                               )\n",
    "            date_string = filename_to_datestring(path)\n",
    "            tracks['video'] = date_string\n",
    "            video_data[path] = (frame_info, detections, tracks)\n",
    "        except ValueError as err: #tritt auf, wenn Video leer ist. In diesem Fall: überspringe video\n",
    "            try:\n",
    "                bad_paths.append(path)\n",
    "                # wir arbeiten später nochmal mit paths, daher müssen das leere löschen, weil sonst\n",
    "                # in video_data kein zugehöriger Value zu Key = file zu finden ist.\n",
    "            except KeyError as err:\n",
    "                continue\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "            raise\n",
    "        # only first vid: break\n",
    "\n",
    "    for bad_path in bad_paths:\n",
    "        paths.remove(bad_path)\n",
    "\n",
    "    #video_data[\"file\"][0] --> frame-info, [1] --> detections, [2] --> tracks\n",
    "    for path in paths:\n",
    "        display_tracking_results(path, video_data[path][0], video_data[path][1], video_data[path][2])\n",
    "\n",
    "    tracks = [video_data[paths[x]][2] for x in range(len(paths))]\n",
    "    tracks = pd.concat(tracks,ignore_index=True)\n",
    "    tracks = tracks.drop(columns=[\"localizerSaliency\", \"beeID\", \"camID\", \"frameIdx\"])\n",
    "\n",
    "    if save_to_csv:\n",
    "        with open(\"tracks.csv\", \"w\") as f:\n",
    "            tracks.to_csv(f)\n",
    "\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a: Create video path list from all videos in videos_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:13:38.157131Z",
     "start_time": "2019-03-19T10:13:38.126224Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Einen Iterable speichern, der alle Videos in einem Iterable zur Verfügung stellt\n",
    "# Diesen Iterable können wir dann in der nächsten Zelle mit tqdm schön durchlaufen\n",
    "base_directory = config[\"videos_dir\"]\n",
    "paths = [i for i in os.listdir(base_directory) if i.endswith(\".h264\")]\n",
    "for i in range(len(paths)):\n",
    "    paths[i] = base_directory + paths[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b: Create video path list from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:13:40.349592Z",
     "start_time": "2019-03-19T10:13:40.116592Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# read in the test data csv\n",
    "test_data = loadGTD(\"bees_test.csv\")\n",
    "\n",
    "all_videos = []\n",
    "\n",
    "all_paths = pd.DataFrame(glob.glob(os.path.join(config[\"videos_dir\"], '*.h264')), columns=['video'])\n",
    "all_paths['video'] = all_paths['video'].apply(lambda x: filename_to_datestring(x))\n",
    "all_paths.sort_values(['video'])\n",
    "\n",
    "# go through test_data and get all videos between timestamp_in and timestamp_out\n",
    "for index, row in test_data.iterrows():\n",
    "    all_videos += get_videos_between(row['video_start_time'],row['video_end_time'], all_paths)\n",
    "    \n",
    "all_videos = sorted(list(set(all_videos)))\n",
    "paths = [datestring_to_filename(x) for x in all_videos]\n",
    "del all_paths\n",
    "del test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue here"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T10:35:09.468983Z",
     "start_time": "2019-03-15T10:35:09.453016Z"
    }
   },
   "source": [
    "tracks = detect_tracks(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zwischenschritt: Merge all close Tracks of one bee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:13:51.199793Z",
     "start_time": "2019-03-19T10:13:51.149940Z"
    }
   },
   "outputs": [],
   "source": [
    "# RUN THIS IF TRACKS WHERE ALREADY CALCULATED AND SAVED TO AN .csv\n",
    "# CSV EINLESEN UND SETZEN\n",
    "tracks = pd.read_csv(\"all_tracks.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:13:52.433581Z",
     "start_time": "2019-03-19T10:13:52.397240Z"
    },
    "code_folding": [
     0,
     39
    ]
   },
   "outputs": [],
   "source": [
    "def gather_tracks(tracks):\n",
    "    \"\"\"\n",
    "    transform the tracks df to : bee_id, [list of positions (x,y)], [list of timestamps], timestamp_of video\n",
    "    \"\"\"\n",
    "\n",
    "    #  transform tracks df to : bee_id, [list of positions (x,y)], [list of timestamps], timestamp_of video\n",
    "    grouped = tracks.groupby(['bee_id','track_id','video'],  as_index=False)['xpos','ypos','timestamp','zrotation']\n",
    "\n",
    "    tracks_ml = grouped.aggregate(lambda x: list(x))\n",
    "\n",
    "    # we don't need track_id anymore\n",
    "    tracks_ml = tracks_ml.drop('track_id', 1)\n",
    "\n",
    "    # add a column: convert video name to timestamp\n",
    "    tracks_ml['video_start_time'] = tracks_ml['video'].apply(lambda x: string_to_timestamp(x))\n",
    "    \n",
    "    # we don't need video anymore\n",
    "    tracks_ml = tracks_ml.drop('video', 1)\n",
    "\n",
    "    # because aggregated: now multiple timestamps per row: --> rename\n",
    "    tracks_ml = tracks_ml.rename(columns={'timestamp': 'timestamps'})\n",
    "\n",
    "    # calculate start time of track by adding timestamp of track (seconds since start of video)\n",
    "    # to timestamp of video (date)\n",
    "    tracks_ml['track_start_time'] = tracks_ml['video_start_time'] + tracks_ml['timestamps'].apply(lambda x: x[0])\n",
    "    tracks_ml['track_end_time'] = tracks_ml['video_start_time'] + tracks_ml['timestamps'].apply(lambda x: x[-1])\n",
    "    \n",
    "    # convert back to string\n",
    "    tracks_ml['video_start_time'] = tracks_ml['video_start_time'].apply(lambda x: timestamp_to_string(x))\n",
    "    \n",
    "    all_paths = pd.DataFrame(glob.glob(os.path.join(config[\"videos_dir\"], '*.h264')), columns=['video'])\n",
    "    all_paths['video'] = all_paths['video'].apply(lambda x: filename_to_datestring(x))\n",
    "    all_paths.sort_values(['video'])\n",
    "    # get end video\n",
    "    tracks_ml['video_end_time'] =  tracks_ml['track_end_time'].apply(lambda x: timestamp_to_string(x))\n",
    "    tracks_ml['video_end_time'] =  tracks_ml[['video_start_time','video_end_time']].apply(lambda x: get_videos_between(x[0],x[1],all_paths)[-1], axis=1)\n",
    "\n",
    "    return tracks_ml\n",
    "\n",
    "def merge_tracks(tracks_ml, verbose = False):\n",
    "    \"\"\"\n",
    "    in: \n",
    "        tracks_ml: output from gather_tracks(tracks)\n",
    "    out:\n",
    "        same df as in, with merged rows\n",
    "        [bee_id:Float, xpos:[Float], ypos:[Float], zrotation:[Float], timestamps:[Float], video_start_time: String,\n",
    "        video_end_time: String, track_start_time:Float, track_end_time:Float]\n",
    "        \n",
    "    merge tracks of same bee where start and end timestamps are close together\n",
    "    assume there can not be overlapping tracks\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # 1. sort: bee_id, start_time\n",
    "    tracks_ml = tracks_ml.sort_values(['bee_id', 'track_start_time'])\n",
    "\n",
    "    \n",
    "    # first convert to timestamp\n",
    "    tracks_ml['video_start_time'] = tracks_ml['video_start_time'].apply(lambda x: string_to_timestamp(x))\n",
    "    \n",
    "    index = 0\n",
    "    while(True):\n",
    "        row = tracks_ml.iloc[index]\n",
    "        next_row = tracks_ml.iloc[index+1]\n",
    "\n",
    "        # if the tracks are from same bee and the start time of next row is closer then 10s -> merge the rows\n",
    "        # merge rows means, next_row is deleted\n",
    "        if (row['bee_id'] == next_row['bee_id']) and ((next_row['track_start_time'] - row['track_end_time']) < 10):\n",
    "            \n",
    "            if verbose:\n",
    "                print(timestamp_to_string(row['video_start_time']), row['bee_id'], next_row['track_start_time'] - row['track_end_time'])\n",
    "                print(next_row['video_start_time'] - row['video_start_time'])\n",
    "                print(timestamp_to_string(row['track_start_time']),timestamp_to_string(row['track_end_time']),timestamp_to_string(row['video_start_time']),row['video_end_time'])\n",
    "                print(row['timestamps'])\n",
    "                print(row.name)\n",
    "                print(timestamp_to_string(next_row['track_start_time']))\n",
    "                print('----------------------------------')\n",
    "           \n",
    "            # update the timestamps of nextrow\n",
    "            t = next_row['video_start_time'] - row['video_start_time']\n",
    "            timestamps = list( np.array(next_row['timestamps']) + t)\n",
    "\n",
    "            # merge xpos, ypos, timestamps lists\n",
    "            tracks_ml.at[row.name,'xpos'] = row['xpos']+next_row['xpos']\n",
    "            tracks_ml.at[row.name,'ypos'] = row['ypos']+next_row['ypos']\n",
    "            tracks_ml.at[row.name,'timestamps'] = row['timestamps']+timestamps\n",
    "\n",
    "            # update end_time\n",
    "            tracks_ml.at[row.name,'track_end_time'] = next_row['track_end_time']\n",
    "            tracks_ml.at[row.name,'video_end_time'] = next_row['video_end_time']\n",
    "\n",
    "            # delete the merged row (next_row)\n",
    "            tracks_ml = tracks_ml.drop(next_row.name).copy()\n",
    "\n",
    "        else:\n",
    "            index += 1\n",
    "        \n",
    "        if index == len(tracks_ml) - 1:\n",
    "            break\n",
    "            \n",
    "    # convert back to string\n",
    "    tracks_ml['video_start_time'] = tracks_ml['video_start_time'].apply(lambda x: timestamp_to_string(x))\n",
    "            \n",
    "    return tracks_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:13:54.391074Z",
     "start_time": "2019-03-19T10:13:53.624702Z"
    }
   },
   "outputs": [],
   "source": [
    "tracks_ml = gather_tracks(tracks)\n",
    "tracks_ml = merge_tracks(tracks_ml)\n",
    "tracks_ml = tracks_ml.sort_values(['video_start_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:13:54.980251Z",
     "start_time": "2019-03-19T10:13:54.495220Z"
    }
   },
   "outputs": [],
   "source": [
    "# read in the test data csv\n",
    "test_data = loadGTD(\"bees_test.csv\")\n",
    "\n",
    "# get all tracks where bee_id, videio_start_time and video_end_time are the same\n",
    "tracks_ml = pd.merge(tracks_ml,test_data,how='inner',on=['bee_id','video_start_time','video_end_time'])\n",
    "\n",
    "# we only look at tracks where  in_direction and out_direction are different\n",
    "tracks_ml = tracks_ml[(tracks_ml['in_direction'] != tracks_ml['out_direction'])]\n",
    "\n",
    "# we assign movement based on in_ and out_directoin\n",
    "tracks_ml.loc[(tracks_ml['in_direction'] == 'left') & (tracks_ml['out_direction'] == 'right'),'movement'] = 1\n",
    "tracks_ml.loc[(tracks_ml['in_direction'] == 'right') & (tracks_ml['out_direction'] == 'left'),'movement'] = 0\n",
    "\n",
    "tracks_ml.drop('in_direction', 1, inplace=True)\n",
    "tracks_ml.drop('out_direction', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline-Algorithmen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithmus 1: Baseline - Areas as Decider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:13:58.369245Z",
     "start_time": "2019-03-19T10:13:58.351466Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\"\"\" Vorgehen:\n",
    "Für jedes Bienen-Track Paar\n",
    "- Prüfe, wo sich die Biene beim ersten erkannten Erscheinen aufhält\n",
    "    - Ordne die Position in left, right oder middle ein\n",
    "- Prüfe, wo sich die Biene beim letzten erkannten Erscheinen aufhält\n",
    "    - Ordne die Position in left, right oder middle ein\n",
    "Wenn sich Biene in der Mitte befindet, starte neue Routine, die links oder rechts zuordnet\n",
    "Daraus kann nun abgeleitet werden, wo die Biene reingekommen ist und wo sie rausgegangen ist.\n",
    "\"\"\"\n",
    "# param: tracks_ml, s. oben\n",
    "def baseline_alg_classify_bee(tracks_ml):\n",
    "    def get_direction(xpos, zpos):\n",
    "        #Helpers\n",
    "        def is_left(xpos):\n",
    "            return xpos <= config[\"left_leaving_area\"]*config[\"px_x_resolution_vid\"]\n",
    "        def is_right(xpos):\n",
    "            return xpos >= config[\"px_x_resolution_vid\"] - config[\"right_leaving_area\"]*config[\"px_x_resolution_vid\"]\n",
    "        # Routine, wenn Biene in der Mitte\n",
    "        # Betrachte zRotation, das ist die Richtung in die die Biene guckt (in Bogenmaß)\n",
    "        # gebe diese Richtung aus\n",
    "        def middle_classifier(zRotation):\n",
    "            if abs(zRotation) > pi/2:\n",
    "                return \"left\"\n",
    "            else:\n",
    "                return \"right\"\n",
    "            \n",
    "        # Eintrittsseite festlegen\n",
    "        if is_left(xpos):\n",
    "            return \"left\"\n",
    "        elif is_right(xpos):\n",
    "            return \"right\"\n",
    "        else:\n",
    "            return middle_classifier(zpos)\n",
    "        \n",
    "    pred_in_direction = len(tracks_ml) * [None]\n",
    "    pred_out_direction = len(tracks_ml) * [None]\n",
    "    i = 0\n",
    "    for index, row in tracks_ml.iterrows():\n",
    "        pred_in_direction[i] = get_direction(row['xpos'][0], row['zrotation'][0])\n",
    "        pred_out_direction[i]= get_direction(row['xpos'][-1], row['zrotation'][-1])\n",
    "        i += 1\n",
    "    \n",
    "    #remove those with no \n",
    "    return pd.DataFrame({\"pred_in_direction\":pred_in_direction, \"pred_out_direction\":pred_out_direction})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Algorithmus 2: Baseline - zpos as decider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T13:39:44.728174Z",
     "start_time": "2019-03-14T13:39:44.716229Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\"\"\" Vorgehen:\n",
    "Unterschied: Hier wird nicht auf die Position abgestellt, sondern ausschließlich auf die\n",
    "Richtung, in die die Biene schaut\n",
    "\"\"\"\n",
    "#results = {\"bee_id\":[], \"time_in\":[], \"os_in\":[], \"time_out\":[], \"os_out\":[], \"in_direction\":[], \"out_direction\":[]}\n",
    "# param: tracks_ml, s. oben\n",
    "def baseline_2_alg_classify_bee(tracks_ml):\n",
    "    def get_in_direction(zpos):\n",
    "        # Betrachte zRotation, das ist die Richtung in die die Biene guckt (in Bogenmaß)\n",
    "        # gebe diese Richtung aus\n",
    "        if zpos > abs(pi/2):\n",
    "            return \"right\"\n",
    "        else:\n",
    "            return \"left\"\n",
    "    def get_out_direction(zpos):\n",
    "        # Betrachte zRotation, das ist die Richtung in die die Biene guckt (in Bogenmaß)\n",
    "        # gebe diese Richtung aus\n",
    "        if zpos > abs(pi/2):\n",
    "            return \"left\"\n",
    "        else:\n",
    "            return \"right\"\n",
    "    \n",
    "    # \"bee_id\":[int], \"time_in\":[String], \"os_in\":[Float], \"time_out\":[String],\n",
    "    # \"os_out\":[Float], \"in_direction\":[{\"left\", \"right\"}], \"out_direction\":[{\"left\", \"right\"}]\n",
    "    results = {\"bee_id\":[], \"time_in\":[], \"os_in\":[], \"time_out\":[], \"os_out\":[], \"in_direction\":[],\n",
    "               \"out_direction\":[]}\n",
    "        \n",
    "    for row in tracks_ml.itertuples(index=False):\n",
    "        results[\"bee_id\"].append(row[0])\n",
    "        results[\"time_in\"].append(row[5])\n",
    "        results[\"os_in\"].append(row[-3] - string_to_timestamp(row[5])) #track_start_time - video_start_time\n",
    "        results[\"time_out\"].append(row[-1])\n",
    "        results[\"os_out\"].append(row[-2] - string_to_timestamp(row[-1])) #track_end_time - video_end_time\n",
    "        results[\"in_direction\"].append(get_in_direction(row[4][0]))\n",
    "        results[\"out_direction\"].append(get_out_direction(row[4][-1]))\n",
    "    \n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T13:39:45.108992Z",
     "start_time": "2019-03-14T13:39:45.081669Z"
    },
    "hidden": true
   },
   "source": [
    "# Ausgeben\n",
    "results = baseline_2_alg_classify_bee(tracks_ml)\n",
    "results = pd.DataFrame(data=results)\n",
    "# write ergebnis to csv\n",
    "results.to_csv('MachineLearnedData.csv', encoding=\"utf-8\", index=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Algorithmus 3: Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Vorbereiten Lernvideos, Prüfvideos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Optional: Tracks um 180° drehen; Tracks horizontal invertieren; Tracks vertikal invertieren (Funktioniert, abhängig von der Wichtigkeit der Zeit als Feature, vielleicht nicht!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T12:41:18.043523Z",
     "start_time": "2019-03-15T12:41:18.038981Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Tracks um 180° drehen\n",
    "track_rotated = tracks_ml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 3.1 Lernen Logistische Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 3.1 Alg: Logistische Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 3.2 Lernen Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 3.2 Alg Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vergleichsfunktion Algorithmus mit Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:14:10.009099Z",
     "start_time": "2019-03-19T10:14:09.945573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 entries in GroundTruthData. 42 entries compareable in MachineLearnedData:  38.89 %\n",
      "71.43 % total correctness.\n",
      "78.57 % Ingoing correctness.\n",
      "92.86 % Outgoing correctness.\n",
      "80.95 % Average correctness.\n",
      "Accuracy of  27.78 %.\n",
      "\n",
      "Check result.csv file or hit 'result' for more details.\n",
      "Use DataFrames for deeper information: \n",
      "'mergeTotalCorrect','mergeInCorrect','mergeOutCorrect','mergeableBees' \n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Input: bees_test.csv, MachineLearnedData.csv\n",
    "Output: \"result\" as DataFrame with an overview of compareable bees and their correct/wrong correctness\n",
    "\n",
    "Read in two csv file and store values in DataFrame's. Merge DataFrame's to get exact correctness of \n",
    "total-, in- and out_direction of bees regarding their time_in and time_out relation. \n",
    "\"\"\"\n",
    "\n",
    "# store data in dataFrame\n",
    "total_gtd = loadGTD('bees_test.csv')\n",
    "gtd = total_gtd.copy()\n",
    "\n",
    "# drop dublicates\n",
    "gtd = gtd.drop_duplicates(['bee_id', 'video_start_time', 'video_end_time'], keep='first')\n",
    "\n",
    "# merge with our tracking output\n",
    "gtd = pd.merge(gtd, tracks_ml, on=['bee_id', 'video_start_time', 'video_end_time'], how='inner')\n",
    "\n",
    "# get result from baseline algorithm\n",
    "mld = baseline_alg_classify_bee(gtd)\n",
    "\n",
    "# iterate mergeableBees for visualization\n",
    "result = pd.DataFrame()\n",
    "result['bee_id'] = gtd['bee_id'] \n",
    "result['in_equals'] = mld['pred_in_direction'] == gtd['in_direction']\n",
    "result['out_equals'] = mld['pred_out_direction'] == gtd['out_direction']\n",
    "\n",
    "# store to result.csv\n",
    "result.to_csv('result.csv', encoding='utf-8', index=False)\n",
    "\n",
    "# calculate statitics\n",
    "inCorrect = round((result['in_equals'].sum()/len(result) * 100), 2)\n",
    "outCorrect = round((result['out_equals'].sum()/len(result) * 100), 2)\n",
    "allCorrect = round(((result['in_equals'] == result['out_equals']).sum()/len(result) * 100), 2)\n",
    "aveCorrect = round(((allCorrect + inCorrect + outCorrect) / 3), 2)\n",
    "\n",
    "# print statistics\n",
    "try:\n",
    "    print(len(total_gtd), 'entries in GroundTruthData.', len(gtd), 'entries compareable in MachineLearnedData: ', round((len(gtd)/len(total_gtd))*100, 2), '%' )\n",
    "    print(allCorrect, \"% total correctness.\")\n",
    "    print(inCorrect, \"% Ingoing correctness.\")\n",
    "    print(outCorrect, \"% Outgoing correctness.\")\n",
    "    print(aveCorrect, \"% Average correctness.\")\n",
    "    print(\"Accuracy of \",round((len(gtd)/len(total_gtd))*100*(allCorrect/100),2),\"%.\")\n",
    "except ZeroDivisionError:\n",
    "    print(\"Nothing to compare!\")\n",
    "\n",
    "# end compare algorithm\n",
    "print('\\nCheck result.csv file or hit \\'result\\' for more details.')\n",
    "print('Use DataFrames for deeper information: \\n\\'mergeTotalCorrect\\',\\'mergeInCorrect\\',\\'mergeOutCorrect\\',\\'mergeableBees\\' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MachineLearnedAlgotithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T11:15:40.971948Z",
     "start_time": "2019-03-19T11:15:40.954265Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "def machineLearning(gtd, pD):\n",
    "    \"\"\" \n",
    "    Input: \n",
    "            GroundTruthData and MachineLearnedData\n",
    "    Output: \n",
    "            Confusion Matrix\n",
    "    \n",
    "    Re-label Input and put information into confusion_matrix method:   \n",
    "    left left -> 0\n",
    "    left right -> 1\n",
    "    right left -> 2\n",
    "    right right -> 3\n",
    "    \"\"\"\n",
    "    \n",
    "    # grap neede columns from gtd\n",
    "    trueData = gtd.copy()\n",
    "    trueData = trueData[['bee_id','in_direction','out_direction']]\n",
    "    \n",
    "    predData = pD.copy()\n",
    "    \n",
    "    # combine directions to one output\n",
    "    def getValue(x,y):\n",
    "        if (x == 'left' and y == 'left'):\n",
    "            return 0\n",
    "        elif (x == 'left' and y == 'right'):\n",
    "            return 1\n",
    "        elif (x == 'right' and y == 'left'):\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "    \n",
    "    # insert reduced information to dataframe\n",
    "    trueData['reduced'] = [int(getValue(x,y)) for (x,y) in zip(trueData['in_direction'], trueData['out_direction'])]\n",
    "    predData['reduced'] = [int(getValue(x,y)) for (x,y) in zip(predData['pred_in_direction'], predData['pred_out_direction'])]\n",
    "    \n",
    "    # confusion Matrix\n",
    "    def computeConfusionMatrix(trueData, predData):\n",
    "        return confusion_matrix(trueData['reduced'], predData['reduced'])\n",
    "\n",
    "    def computeRandomForest(trueData, predData):\n",
    "        # use predData['reduced'] as training and test data\n",
    "        train, test = predData[predData['reduced'] <= 2], predData[predData['reduced'] > 2]\n",
    "        \n",
    "        print('Number of observations in the training data:', len(train))\n",
    "        print('Number of observations in the test data:',len(test))\n",
    "        \n",
    "        y = pd.factorize(train['reduced'])[0]\n",
    "        print(y)\n",
    "        \n",
    "        features = predData.columns[0:2]\n",
    "        clf = RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "        clf.fit(train[features], predData['reduced'])\n",
    "        \n",
    "    print (computeConfusionMatrix(trueData, predData))\n",
    "    print (computeRandomForest(trueData, predData))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T11:15:41.694982Z",
     "start_time": "2019-03-19T11:15:41.178243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0]\n",
      " [ 3 17  0  5]\n",
      " [ 4  0 13  0]\n",
      " [ 0  0  0  0]]\n",
      "Number of observations in the training data: 37\n",
      "Number of observations in the test data: 5\n",
      "[0 0 1 1 2 0 2 2 0 0 1 1 1 0 0 0 0 0 2 1 2 0 0 0 0 1 1 0 2 1 0 1 1 1 0 1 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ronnyruhe/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'left'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-8aafa0611443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#gtd = mergeTotalCorrect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmachineLearning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgtd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmld\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-112-6712daedbe11>\u001b[0m in \u001b[0;36mmachineLearning\u001b[0;34m(gtd, pD)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomputeConfusionMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrueData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomputeRandomForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrueData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-112-6712daedbe11>\u001b[0m in \u001b[0;36mcomputeRandomForest\u001b[0;34m(trueData, predData)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reduced'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomputeConfusionMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrueData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'left'"
     ]
    }
   ],
   "source": [
    "#gtd = mergeTotalCorrect\n",
    "print(machineLearning(gtd, mld))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
